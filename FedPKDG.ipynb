{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPai5eV2CmtFeKv4h6DeNBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisW2420/FedPKDG/blob/main/FedPKDG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FedPKDG -- Prune + KD + GAN + FL\n",
        "This prototype implements the algorithm in a distributed setting\n",
        "TODO:\n",
        "1. implement a FedAvg aggregator/server\n",
        "2. build a centralised FL system with n clients connected to the server\n",
        "3. design experiments to assess accuracy, efficiency, generalisation on homogenoeous data\n",
        "4. repeat experiments on heterogeneous data, identical model sparsity\n",
        "5. repeat experiments on heterogeneous data, different model sparsity, mimicing different computational capability of clients"
      ],
      "metadata": {
        "id": "GR5F2i850OT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Imports"
      ],
      "metadata": {
        "id": "0qqRJILKrnul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NB: package versions are very important\n",
        "!pip install -q tensorflow-model-optimization # for pruning\n",
        "!pip install -q git+https://github.com/tensorflow/docs # newest tf\n",
        "!pip install --upgrade keras #newest keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgElPEcBrp3j",
        "outputId": "0d3d7d5e-cf81-4e5f-e37b-5e4916844de8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m174.1/242.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Collecting optree (from keras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, optree, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.3.3 namex-0.0.8 optree-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 versions of keras are used for different functionalities, imported as different names\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "import tf_keras as keras_model #only for pruning\n",
        "from tf_keras import layers as model_layers\n",
        "import keras\n",
        "import tempfile\n",
        "from tf_keras.callbacks import EarlyStopping, Callback\n",
        "from keras import ops, layers\n",
        "from tensorflow_docs.vis import embed # for GAN\n",
        "import matplotlib.pyplot as plt\n",
        "from tf_keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "0uN9jtQssMKu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging metrics with WandB\n",
        "\n",
        "# !pip install wandb\n",
        "# import wandb\n",
        "# wandb.login()\n",
        "# from wandb.keras import WandbMetricsLogger"
      ],
      "metadata": {
        "id": "yLSfMJe-spr2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "lDJsxBBKO5k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST\n",
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "S5AEP2kXO7Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6974b7-347d-4322-af2e-7b26e41780cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Components Implementation"
      ],
      "metadata": {
        "id": "UDusEhV8rad4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model zoo"
      ],
      "metadata": {
        "id": "yivLHBBVKZ7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "LiDzieUBHTED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def miniCNN():\n",
        "  model = keras_model.Sequential(\n",
        "      [\n",
        "          keras_model.Input(shape=(28, 28, 1)),\n",
        "          model_layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.Flatten(),\n",
        "          model_layers.Dense(10),\n",
        "      ],\n",
        "      name=\"minicnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def smallCNN():\n",
        "  model = keras_model.Sequential(\n",
        "      [\n",
        "          keras_model.Input(shape=(28, 28, 1)),\n",
        "          model_layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.LeakyReLU(alpha=0.2),\n",
        "          model_layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          model_layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.Flatten(),\n",
        "          model_layers.Dense(10),\n",
        "      ],\n",
        "      name=\"smallcnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def mediumCNN():\n",
        "  model = keras_model.Sequential(\n",
        "      [\n",
        "          keras_model.Input(shape=(28, 28, 1)),\n",
        "          model_layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.LeakyReLU(alpha=0.2),\n",
        "          model_layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          model_layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.LeakyReLU(alpha=0.2),\n",
        "          model_layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          model_layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.Flatten(),\n",
        "          model_layers.Dense(10),\n",
        "      ],\n",
        "      name=\"mediumcnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def bigCNN():\n",
        "  model = keras_model.Sequential(\n",
        "      [\n",
        "          keras_model.Input(shape=(28, 28, 1)),\n",
        "          model_layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.LeakyReLU(alpha=0.2),\n",
        "          model_layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          model_layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.LeakyReLU(alpha=0.2),\n",
        "          model_layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          model_layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          model_layers.Flatten(),\n",
        "          model_layers.Dense(10),\n",
        "      ],\n",
        "      name=\"bigcnn\",\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZU1h8xrMKcWX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN"
      ],
      "metadata": {
        "id": "2Yeo7R7OHVFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_channels = 1\n",
        "num_classes = 10\n",
        "image_size = 28\n",
        "latent_dim = 128 # hyperparam, can tune\n",
        "\n",
        "generator_in_channels = latent_dim + num_classes\n",
        "discriminator_in_channels = num_channels + num_classes\n",
        "\n",
        "# Create the discriminator.\n",
        "def Discriminator(latent_dim = 128):\n",
        "  discriminator = keras.Sequential(\n",
        "      [\n",
        "          keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
        "          layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          layers.LeakyReLU(negative_slope=0.2),\n",
        "          layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          layers.LeakyReLU(negative_slope=0.2),\n",
        "          layers.GlobalMaxPooling2D(),\n",
        "          layers.Dense(1),\n",
        "      ],\n",
        "      name=\"discriminator\",\n",
        "  )\n",
        "  return discriminator\n",
        "\n",
        "# Create the generator.\n",
        "def Generator():\n",
        "  generator = keras.Sequential(\n",
        "      [\n",
        "          keras.layers.InputLayer((generator_in_channels,)),\n",
        "          # We want to generate 128 + num_classes coefficients to reshape into a\n",
        "          # 7x7x(128 + num_classes) map.\n",
        "          layers.Dense(7 * 7 * generator_in_channels),\n",
        "          layers.LeakyReLU(negative_slope=0.2),\n",
        "          layers.Reshape((7, 7, generator_in_channels)),\n",
        "          layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "          layers.LeakyReLU(negative_slope=0.2),\n",
        "          layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "          layers.LeakyReLU(negative_slope=0.2),\n",
        "          layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "      ],\n",
        "      name=\"generator\",\n",
        "  )\n",
        "  return generator"
      ],
      "metadata": {
        "id": "ZvYMNrI8HWna"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN"
      ],
      "metadata": {
        "id": "C9du692bJ1GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalGAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        real_images, one_hot_labels = data\n",
        "\n",
        "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
        "        # the images. This is for the discriminator.\n",
        "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "        image_one_hot_labels = ops.repeat(\n",
        "            image_one_hot_labels, repeats=[image_size * image_size]\n",
        "        )\n",
        "        image_one_hot_labels = ops.reshape(\n",
        "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space and concatenate the labels.\n",
        "        # This is for the generator.\n",
        "        batch_size = ops.shape(real_images)[0]\n",
        "        random_latent_vectors = keras.random.normal(\n",
        "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
        "        )\n",
        "        random_vector_labels = ops.concatenate(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Decode the noise (guided by labels) to fake images.\n",
        "        generated_images = self.generator(random_vector_labels)\n",
        "\n",
        "        # Combine them with real images. Note that we are concatenating the labels\n",
        "        # with these images here.\n",
        "        fake_image_and_labels = ops.concatenate(\n",
        "            [generated_images, image_one_hot_labels], -1\n",
        "        )\n",
        "        real_image_and_labels = ops.concatenate([real_images, image_one_hot_labels], -1)\n",
        "        combined_images = ops.concatenate(\n",
        "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
        "        )\n",
        "\n",
        "        # Assemble labels discriminating real from fake images.\n",
        "        labels = ops.concatenate(\n",
        "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # Train the discriminator.\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space.\n",
        "        random_latent_vectors = keras.random.normal(\n",
        "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
        "        )\n",
        "        random_vector_labels = ops.concatenate(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Assemble labels that say \"all real images\".\n",
        "        misleading_labels = ops.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_vector_labels)\n",
        "            fake_image_and_labels = ops.concatenate(\n",
        "                [fake_images, image_one_hot_labels], -1\n",
        "            )\n",
        "            predictions = self.discriminator(fake_image_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "dimSAKxdJ9jq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image generation functions\n",
        "def generate_image(generator, target_class, latent_dim):\n",
        "    noise_matrix = keras.random.normal(shape=(1, latent_dim))\n",
        "    # Convert the target label to one-hot encoded vectors.\n",
        "    target_label = keras.utils.to_categorical([target_class], num_classes)\n",
        "    target_label = ops.cast(target_label, \"float32\")\n",
        "    noise_and_labels = ops.concatenate([noise_matrix, target_label], 1)\n",
        "    fake = generator.predict(noise_and_labels,verbose = 0)\n",
        "    return fake\n",
        "\n",
        "\n",
        "def dataAugmentation(x_initial, y_initial, num_augimg, batch_size):\n",
        "  datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.1,\n",
        "      zoom_range=0.1\n",
        "  )\n",
        "\n",
        "  # Create empty arrays to store the augmented data\n",
        "  augmented_images = np.empty((num_augimg, 28, 28, 1), dtype=np.float32)\n",
        "  augmented_labels = np.empty((num_augimg,), dtype=np.int32)\n",
        "\n",
        "  # Generate the augmented dataset\n",
        "  num_batches = num_augimg // batch_size\n",
        "  counter = 0\n",
        "\n",
        "  for x_batch, y_batch in datagen.flow(x_initial, y_initial, batch_size=batch_size):\n",
        "      augmented_images[counter*batch_size:(counter+1)*batch_size] = x_batch\n",
        "      augmented_labels[counter*batch_size:(counter+1)*batch_size] = y_batch\n",
        "      counter += 1\n",
        "      if counter >= num_batches:\n",
        "          break\n",
        "\n",
        "  # Verify the shape of the augmented dataset\n",
        "  print(f\"Augmented dataset shape: {augmented_images.shape}, {augmented_labels.shape}\")\n",
        "\n",
        "  # Optionally, combine the augmented data with the original training data\n",
        "  combined_images = np.concatenate((x_initial, augmented_images), axis=0)\n",
        "  combined_labels = np.concatenate((y_initial, augmented_labels), axis=0)\n",
        "  return combined_images, combined_labels\n",
        "\n",
        "\n",
        "def pseudoDataset(generator, total_num, latent_dim, is_augment=True, batch_size=64): # producing equal numbers of samples for each class\n",
        "    pseudo_images = []\n",
        "    if is_augment:\n",
        "      total_num = total_num//2\n",
        "    for num in range(10):\n",
        "      target_class = num\n",
        "      print('Generating', int(total_num/10), 'fake images of digit', num, '......')\n",
        "      for _ in range(int(total_num/10)):\n",
        "        generated_images = generate_image(generator, target_class, latent_dim)\n",
        "        generated_images *= 255.0\n",
        "        converted_images = generated_images.astype(np.uint8)\n",
        "        converted_images = ops.image.resize(converted_images, (28, 28)).numpy().astype(np.uint8)\n",
        "        pseudo_images.append(converted_images)\n",
        "    pseudo_images = np.concatenate(pseudo_images, axis=0)\n",
        "    x_pseudo = pseudo_images.astype(\"float32\") / 255.0\n",
        "    x_pseudo = np.reshape(x_pseudo, (-1, 28, 28, 1))\n",
        "    pseudo_labels = np.repeat(np.arange(10), int(total_num/10))\n",
        "\n",
        "    if is_augment:\n",
        "      x_pseudo, pseudo_labels = dataAugmentation(x_pseudo, pseudo_labels, total_num, batch_size) #1:1 augmentation to true ratio\n",
        "\n",
        "    print('Added', pseudo_labels.shape, 'data points to the public dataset')\n",
        "    return x_pseudo, pseudo_labels"
      ],
      "metadata": {
        "id": "IYYsK1c3nEry"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning"
      ],
      "metadata": {
        "id": "EZI_-kzpJ4OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_finetrain(base_model, _epochs, x, y, target_sparsity, fine_tune_epochs, validation_split=0.1):\n",
        "  callbacks = [\n",
        "      sparsity.UpdatePruningStep(),\n",
        "      early_stopping\n",
        "  ]\n",
        "  steps_per_epoch = len(x)*(1-validation_split) // batch_size\n",
        "  begin_step=int(steps_per_epoch*fine_tune_epochs)\n",
        "  end_step=int(steps_per_epoch*_epochs)+1\n",
        "  print('begin_step=', begin_step, 'end_step=', end_step)\n",
        "  pruning_schedule = sparsity.PolynomialDecay(initial_sparsity=0, final_sparsity=target_sparsity,\n",
        "                                              begin_step=begin_step, end_step=end_step) # TODO: tune begin_step, consider fining training before starting to prune\n",
        "\n",
        "  model_for_pruning = sparsity.prune_low_magnitude(base_model, pruning_schedule=pruning_schedule) #default constant sparsity of 50%\n",
        "\n",
        "  model_for_pruning.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras_model.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras_model.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model_for_pruning.fit(\n",
        "      x,\n",
        "      y,\n",
        "      batch_size=batch_size,\n",
        "      validation_split=validation_split,\n",
        "      callbacks=callbacks,\n",
        "      epochs=_epochs,\n",
        "  )\n",
        "  pruned_model = sparsity.strip_pruning(model_for_pruning)\n",
        "\n",
        "  return pruned_model\n",
        "\n",
        "\n",
        "# Model size metrics\n",
        "\n",
        "def get_model_sparsity(model):\n",
        "    total_weights = 0\n",
        "    zero_weights = 0\n",
        "    for weight in model.get_weights():\n",
        "        total_weights += weight.size\n",
        "        zero_weights += np.count_nonzero(weight == 0)\n",
        "    return zero_weights / total_weights\n",
        "\n",
        "def get_gzipped_model_size(model):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, keras_file = tempfile.mkstemp('.h5')\n",
        "  model.save(keras_file, include_optimizer=False)\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(keras_file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "oxgClZVAJ-Y2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation"
      ],
      "metadata": {
        "id": "m0uflogyJ53G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras_model.Model):\n",
        "    def __init__(self, get_teacher_logits, student, alpha=0.1, temperature=3, **kwargs):\n",
        "        super(Distiller, self).__init__(**kwargs)\n",
        "        self.student = student\n",
        "        self.get_teacher_logits = get_teacher_logits\n",
        "\n",
        "    def compile(self, optimizer, metrics, student_loss_fn, distillation_loss_fn, alpha, temperature, **kwargs):\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics, **kwargs)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.student.compile(optimizer=optimizer, metrics=metrics, loss=self.student_loss_fn)\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        teacher_predictions = self.get_teacher_logits(x)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of the student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Calculate the task-specific loss\n",
        "            task_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "            # Calculate the soft targets and the distillation loss\n",
        "            soft_targets = tf.nn.softmax(teacher_predictions / self.temperature)\n",
        "\n",
        "            student_soft = tf.nn.softmax(student_predictions / self.temperature)\n",
        "            distillation_loss = self.distillation_loss_fn(soft_targets, student_soft)\n",
        "\n",
        "            # Calculate the total loss\n",
        "            total_loss = (1 - self.alpha) * task_loss + self.alpha * distillation_loss * (self.temperature ** 2)\n",
        "\n",
        "        # Compute gradients and update weights\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(total_loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update metrics\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"task_loss\": task_loss, \"distillation_loss\": distillation_loss, \"total_loss\": total_loss})\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of the student\n",
        "        y_pred = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the task-specific loss\n",
        "        task_loss = self.student_loss_fn(y, y_pred)\n",
        "\n",
        "        # Update the metrics\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def call_model(self):\n",
        "      return self.student"
      ],
      "metadata": {
        "id": "BNTcgLrs0PmV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Function Implementation\n",
        "\n",
        "TODO:\n",
        "Dataset:\n",
        "- Dataloader\n",
        "- heterogeneous dataset partition\n",
        "- data augmentation\n",
        "\n",
        "visualisation:\n",
        "- dataset example visualisation\n",
        "- data distribution visualisation\n",
        "- confusion matrix\n",
        "-"
      ],
      "metadata": {
        "id": "rtt0HHPp6bWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_model_weights_to_zero(model):\n",
        "    for layer in model.layers:\n",
        "        zero_weights = [np.zeros_like(w) for w in layer.get_weights()]\n",
        "        layer.set_weights(zero_weights)\n",
        "    return model"
      ],
      "metadata": {
        "id": "pL7iWz7Z6ew6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def if_synced(model1, model2):\n",
        "    for layer1, layer2 in zip(model1.layers, model2.layers):\n",
        "          weights1 = layer1.get_weights()\n",
        "          weights2 = layer2.get_weights()\n",
        "          for w1, w2 in zip(weights1, weights2):\n",
        "              if not np.array_equal(w1, w2):\n",
        "                  print('different weights, syncing failed')\n",
        "    print('weights synced for client')"
      ],
      "metadata": {
        "id": "5nd729kbESwD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback zoo"
      ],
      "metadata": {
        "id": "0_Ji1-THrXgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss', #default to val_loss\n",
        "    min_delta=0.001,  # only consider as improvement significant changes\n",
        "    patience=2,      # number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='min'        # 'min' because we want to minimize the loss\n",
        "    )"
      ],
      "metadata": {
        "id": "9di4sjQurWkv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client"
      ],
      "metadata": {
        "id": "0XwMW_rz5C_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Client(): #TODO: add name to clients to refer to them, espeically during logging\n",
        "  def __init__(self, model_fn, x_train, y_train, **kwargs): #generator = None, discriminator = None, self.latent_dim = 128\n",
        "    self.cnn = model_fn\n",
        "    self.generator = Generator()\n",
        "    self.discriminator = Discriminator()\n",
        "    self.latent_dim = 128\n",
        "    self.x_private = x_train\n",
        "    self.y_private = y_train\n",
        "    self.batch_size = 64 # hyperparam, can tune\n",
        "    self.validation_split=0.1\n",
        "\n",
        "  def train_cnn(self, epochs = 5, is_prune = False, target_sparsity = 0.3, fine_tune_epochs = 0, **kwargs):\n",
        "    if is_prune:\n",
        "      print('from gloabl - before pruning client has sparsity', get_model_sparsity(self.cnn))\n",
        "      self.cnn = prune_finetrain(self.cnn, _epochs = epochs, x = self.x_private, y = self.y_private, target_sparsity = target_sparsity, fine_tune_epochs = fine_tune_epochs) # fine_tune_epochs can take decimals, starts pruning after fine tune\n",
        "      self.cnn.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras_model.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras_model.metrics.SparseCategoricalAccuracy()]\n",
        "      )\n",
        "      print('after pruning client has sparsity', get_model_sparsity(self.cnn))\n",
        "    else:\n",
        "      self.cnn.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras_model.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras_model.metrics.SparseCategoricalAccuracy()]\n",
        "      )\n",
        "      self.cnn.fit(self.x_private, self.y_private, batch_size=batch_size, epochs=epochs,validation_split=self.validation_split, callbacks=[early_stopping])\n",
        "\n",
        "  def train_gen(self, epochs = 20, d_learning_rate = 0.0003, g_learning_rate = 0.0003):\n",
        "    cond_gan = ConditionalGAN(self.discriminator, self.generator, self.latent_dim)\n",
        "    cond_gan.compile(\n",
        "        d_optimizer=keras.optimizers.Adam(d_learning_rate),\n",
        "        g_optimizer=keras.optimizers.Adam(g_learning_rate),\n",
        "        loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    )\n",
        "    # produce GAN training dataset\n",
        "    train_label = keras.utils.to_categorical(self.y_private, 10) # 1 hot encoding label\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((self.x_private, train_label))\n",
        "    dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "    cond_gan.fit(dataset, epochs=epochs, callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "  ## the following code act as interface with the server, avoid direct access to private model and dataset\n",
        "\n",
        "  def produce_logits(self, x): #for KD\n",
        "    logits = self.cnn(x, training=False)\n",
        "    print('----getting 1 client logits')\n",
        "    return logits\n",
        "\n",
        "  def get_cnn_weights(self): #only for FedAvg, disabled\n",
        "    return self.cnn.get_weights()\n",
        "\n",
        "  def get_cnn_classifier(self):\n",
        "    return self.cnn.layers[-1].get_weights()\n",
        "\n",
        "  def set_cnn_weights(self, weights): #for downloading global weights\n",
        "    self.cnn.set_weights(weights)\n",
        "\n",
        "  def get_gen_weights(self): #only for FedAvg, disabled\n",
        "    return self.generator.get_weights()\n",
        "\n",
        "  def set_gen_weights(self, weights): #for downloading global weights\n",
        "    self.generator.set_weights(weights)\n",
        "\n",
        "  def get_datasize(self):\n",
        "    return self.x_private.shape[0]"
      ],
      "metadata": {
        "id": "oYQ-XPX05CW2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Server"
      ],
      "metadata": {
        "id": "8RMvpBJwLuju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Server():\n",
        "  def __init__(self, model_fn, client_list, comm_freq = 1, algo = 'FedAvg', **kwargs): #generator = None,\n",
        "    self.cnn = model_fn\n",
        "    self.client_list = client_list # calling this param when \"uploading\" or \"downloading\"\n",
        "    self.client_datasize = []\n",
        "    self.generator = Generator()\n",
        "    self.latent_dim = 128 # hyperparam, can tune\n",
        "    self.x_public = np.array([]) # to generate\n",
        "    self.y_public = np.array([]) # to generate\n",
        "    self.batch_size = 64 # hyperparam, can tune\n",
        "    self.comm_freq = comm_freq # no. of client local training epochs before upload\n",
        "\n",
        "    # default settings for FedAvg\n",
        "    self.is_prune = False\n",
        "    self.is_simKD = False\n",
        "\n",
        "    if algo == 'FedPKDG':\n",
        "    # turn on FedPKDG\n",
        "      self.is_prune = True\n",
        "      self.is_simKD = True\n",
        "\n",
        "  def get_client_datasize(self):\n",
        "    if len(self.client_datasize) != len(self.client_list):\n",
        "      for i in range(len(self.client_datasize), len(self.client_list)):\n",
        "        self.client_datasize.append(self.client_list[i].get_datasize())\n",
        "    return self.client_datasize\n",
        "\n",
        "  def assign_weights_cnn(self, client):\n",
        "    client.set_cnn_weights(self.cnn.get_weights())\n",
        "\n",
        "  def assign_weights_gen(self, client):\n",
        "    client.set_gen_weights(self.generator.get_weights())\n",
        "\n",
        "  def broadcast(self):\n",
        "    # TODO: improve: can use tff.federated_map and tff.federated_broadcast, can combine the two assign fns\n",
        "    for client in self.client_list:\n",
        "        self.assign_weights_cnn(client)\n",
        "    for client in self.client_list:\n",
        "        self.assign_weights_gen(client)\n",
        "\n",
        "  def local_training(self, cnn_epochs=None, target_sparsity=0.3, fine_tune_epochs = 0, gen_epochs=None):\n",
        "    for idx, client in enumerate(self.client_list):\n",
        "      # train the cnn\n",
        "      print('training client', idx, '\\'s CNN')\n",
        "      if not cnn_epochs:\n",
        "        cnn_epochs = self.comm_freq\n",
        "      client.train_cnn(epochs = cnn_epochs, is_prune = self.is_prune, target_sparsity=target_sparsity, fine_tune_epochs = fine_tune_epochs)\n",
        "      # train the generator\n",
        "      print('training client', idx, '\\'s GEN')\n",
        "      if not gen_epochs:\n",
        "        gen_epochs = self.comm_freq\n",
        "      client.train_gen(epochs = gen_epochs)\n",
        "\n",
        "  def weighted_average(self, type_of_value ,output):\n",
        "    print('----getting weighted avg of clients\\'', type_of_value)\n",
        "    p = self.get_client_datasize()\n",
        "    total_size = sum(p)\n",
        "    for client_idx, client in enumerate(self.client_list):\n",
        "        p_k = p[client_idx]/total_size\n",
        "        if type_of_value == 'cnn':\n",
        "          client_val = client.get_cnn_weights()\n",
        "        elif type_of_value == 'gen':\n",
        "          client_val = client.get_gen_weights()\n",
        "        elif type_of_value == 'classifier':\n",
        "          client_val = client.get_cnn_classifier()\n",
        "        for val_idx, value in enumerate(client_val):\n",
        "          output[val_idx] += p_k * value\n",
        "    return output\n",
        "\n",
        "  def agg_cnn(self):\n",
        "    global_weights = [np.zeros_like(w) for w in self.cnn.get_weights()]\n",
        "    global_weights = self.weighted_average('cnn', global_weights)\n",
        "    # Set the updated weights to the global model\n",
        "    self.cnn.set_weights(global_weights)\n",
        "\n",
        "  def agg_classifier(self):\n",
        "    # !!TODO: to test, can use tff.federated_mean\n",
        "    global_weights = [np.zeros_like(w) for w in self.cnn.layers[-1].get_weights()]\n",
        "    global_weights = self.weighted_average('classifier', global_weights)\n",
        "    # Set the updated weights to the global model\n",
        "    self.cnn.layers[-1].set_weights(global_weights)\n",
        "    self.cnn.layers[-1].trainable = False\n",
        "\n",
        "  def agg_gen(self):\n",
        "    global_weights = [np.zeros_like(w) for w in self.generator.get_weights()]\n",
        "    global_weights = self.weighted_average('gen', global_weights)\n",
        "    # Set the updated weights to the global model\n",
        "    self.generator.set_weights(global_weights)\n",
        "\n",
        "  def produce_pseudo_dataset(self, total_num = None):\n",
        "    # generate with gen, homogenous data: equal number of datapoints for each class\n",
        "    #TODO: test pseudoDataset\n",
        "    if total_num == None:\n",
        "      total_num = min(self.client_datasize)\n",
        "    if self.x_public.size==0:\n",
        "      self.x_public, self.y_public = pseudoDataset(generator=self.generator, total_num=total_num, latent_dim=self.latent_dim)\n",
        "    else:\n",
        "      new_x, new_y = pseudoDataset(generator=self.generator, total_num=5*self.batch_size, latent_dim=self.latent_dim)\n",
        "      self.x_public = np.concatenate((self.x_public, new_x), axis=0)\n",
        "      self.y_public = np.concatenate((self.y_public, new_y), axis=0)\n",
        "\n",
        "  def agg_logits(self, data):\n",
        "    # mimics clients sending their logits to the server given the same input\n",
        "    p = self.get_client_datasize()\n",
        "    total_size = sum(p)\n",
        "    for client_idx, client in enumerate(self.client_list):\n",
        "      p_k = p[client_idx]/total_size\n",
        "      if client_idx == 0:\n",
        "        logits = p_k * client.produce_logits(data)\n",
        "      else:\n",
        "        logits += p_k * client.produce_logits(data)\n",
        "    print('----getting aggregate client logits',logits)\n",
        "    return logits\n",
        "\n",
        "  def distill_to_global(self, epochs=3):\n",
        "    #!!!TODO: test distillation based on the public_dataset and agg_logits\n",
        "    if self.is_simKD:\n",
        "      self.agg_classifier()\n",
        "    distiller = Distiller(get_teacher_logits = self.agg_logits, student = self.cnn)\n",
        "    distiller.compile(\n",
        "      optimizer=keras_model.optimizers.Adam(),\n",
        "      metrics=[keras_model.metrics.SparseCategoricalAccuracy()],\n",
        "      student_loss_fn=keras_model.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      distillation_loss_fn=keras_model.losses.KLDivergence(),\n",
        "      alpha=0.4,\n",
        "      temperature=3,\n",
        "    )\n",
        "    # Distill teacher to student\n",
        "    distiller.fit(self.x_public, self.y_public, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    print('should print not trainable:', self.cnn.layers[-1].trainable)\n",
        "    self.cnn.layers[-1].trainable = True\n",
        "    print('should print trainable:', self.cnn.layers[-1].trainable)"
      ],
      "metadata": {
        "id": "33NE17U-Xr72"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Functionality\n",
        "\n",
        "NB: re-run the server block before every experiment to avoid error: Server class not callable"
      ],
      "metadata": {
        "id": "kTbXJ45XOzCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FedAvg (Don't Touch)"
      ],
      "metadata": {
        "id": "2jO8wgGy-e62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initiate 3 clients\n",
        "no_sample = len(x_train) // 3\n",
        "client_list = []\n",
        "for i in range(3):\n",
        "  #partition dataset to mimic private data\n",
        "  x_train_k = x_train[no_sample*i:no_sample*(i+1)]\n",
        "  y_train_k = y_train[no_sample*i:no_sample*(i+1)]\n",
        "  client_list.append(Client(smallCNN(), x_train_k, y_train_k))\n",
        "\n",
        "#initiate 1 server\n",
        "Server = Server(smallCNN(), client_list, comm_freq = 1)\n",
        "\n",
        "for _ in range(3):\n",
        "  Server.broadcast()\n",
        "  print('Broadcasted weights to all clients')\n",
        "  Server.local_training()\n",
        "  print('trained all clients cnn round', _)\n",
        "  Server.agg_cnn()\n",
        "  print('Weighted aggregated client weights')\n",
        "\n",
        "for client in client_list:\n",
        "  client.cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wx11C-UO0WO",
        "outputId": "af09b480-7040-4a81-be40-cad918d7b828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcasted weights to all clients\n",
            "training client 0 's cnn\n",
            "282/282 [==============================] - 6s 14ms/step - loss: 0.8666 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.3297 - val_sparse_categorical_accuracy: 0.9050\n",
            "training client 1 's cnn\n",
            "282/282 [==============================] - 5s 11ms/step - loss: 0.8512 - sparse_categorical_accuracy: 0.7609 - val_loss: 0.3672 - val_sparse_categorical_accuracy: 0.8970\n",
            "training client 2 's cnn\n",
            "282/282 [==============================] - 7s 19ms/step - loss: 0.8463 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.2613 - val_sparse_categorical_accuracy: 0.9210\n",
            "trained all clients cnn round 0\n",
            "Weighted aggregated client weights\n",
            "Broadcasted weights to all clients\n",
            "training client 0 's cnn\n",
            "282/282 [==============================] - 6s 14ms/step - loss: 0.3540 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.2673 - val_sparse_categorical_accuracy: 0.9210\n",
            "training client 1 's cnn\n",
            "282/282 [==============================] - 6s 12ms/step - loss: 0.3558 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.3160 - val_sparse_categorical_accuracy: 0.9030\n",
            "training client 2 's cnn\n",
            "282/282 [==============================] - 5s 11ms/step - loss: 0.3469 - sparse_categorical_accuracy: 0.8948 - val_loss: 0.2162 - val_sparse_categorical_accuracy: 0.9395\n",
            "trained all clients cnn round 1\n",
            "Weighted aggregated client weights\n",
            "Broadcasted weights to all clients\n",
            "training client 0 's cnn\n",
            "282/282 [==============================] - 5s 12ms/step - loss: 0.3004 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.2268 - val_sparse_categorical_accuracy: 0.9405\n",
            "training client 1 's cnn\n",
            "282/282 [==============================] - 5s 12ms/step - loss: 0.2983 - sparse_categorical_accuracy: 0.9122 - val_loss: 0.2671 - val_sparse_categorical_accuracy: 0.9180\n",
            "training client 2 's cnn\n",
            "282/282 [==============================] - 5s 11ms/step - loss: 0.2941 - sparse_categorical_accuracy: 0.9113 - val_loss: 0.1745 - val_sparse_categorical_accuracy: 0.9555\n",
            "trained all clients cnn round 2\n",
            "Weighted aggregated client weights\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2496 - sparse_categorical_accuracy: 0.9256\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2495 - sparse_categorical_accuracy: 0.9265\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.9260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_k = x_train[:no_sample]\n",
        "y_train_k = y_train[:no_sample]\n",
        "client = Client(smallCNN(), x_train_k, y_train_k)\n",
        "client.local_train(epochs=3)\n",
        "client.cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clXt_GxJD99-",
        "outputId": "9c82cf31-09b6-4fc8-da57-1822796ea9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "282/282 [==============================] - 5s 14ms/step - loss: 0.7805 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.3458 - val_sparse_categorical_accuracy: 0.9010\n",
            "Epoch 2/3\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.3653 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.9185\n",
            "Epoch 3/3\n",
            "282/282 [==============================] - 3s 10ms/step - loss: 0.3179 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.9245\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2903 - sparse_categorical_accuracy: 0.9135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29031461477279663, 0.9135000109672546]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment: model quickly overfit to bad training data even after syncing weights, need to prevent this"
      ],
      "metadata": {
        "id": "Q5h6K_slalno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just Pruning (Don't Touch)"
      ],
      "metadata": {
        "id": "5nKDiEwT-ayP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_sample = len(x_train) // 3\n",
        "client_list = []\n",
        "for i in range(3):\n",
        "  #partition dataset to mimic private data\n",
        "  x_train_k = x_train[no_sample*i:no_sample*(i+1)]\n",
        "  y_train_k = y_train[no_sample*i:no_sample*(i+1)]\n",
        "  client_list.append(Client(smallCNN(), x_train_k, y_train_k))\n",
        "\n",
        "#initiate 1 server\n",
        "Server = Server(smallCNN(), client_list, comm_freq = 1, algo = 'FedPKDG')\n",
        "\n",
        "for _ in range(3):\n",
        "  Server.broadcast()\n",
        "  print('Broadcasted weights to all clients')\n",
        "  Server.local_training()\n",
        "  print('trained all clients cnn round', _)\n",
        "  Server.agg_cnn()\n",
        "  print('Weighted aggregated client weights')\n",
        "\n",
        "for client in client_list:\n",
        "  get_model_sparsity(client.cnn)\n",
        "  client.cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSmgBFBa-lYt",
        "outputId": "689400d5-ee9b-478b-ee69-0a9220d096f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after broadcasting client has sparsity 0.0056595559425337396\n",
            "after broadcasting client has sparsity 0.0056595559425337396\n",
            "after broadcasting client has sparsity 0.0056595559425337396\n",
            "Broadcasted weights to all clients\n",
            "training client 0 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 9s 13ms/step - loss: 0.8240 - sparse_categorical_accuracy: 0.7577 - val_loss: 0.3441 - val_sparse_categorical_accuracy: 0.8970\n",
            "training client 1 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 9s 18ms/step - loss: 0.8242 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.4127 - val_sparse_categorical_accuracy: 0.8890\n",
            "training client 2 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 7s 12ms/step - loss: 0.8215 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.2855 - val_sparse_categorical_accuracy: 0.9250\n",
            "trained all clients cnn round 0\n",
            "before agg client 0 has sparsity 0.4849804092294297\n",
            "before agg client 1 has sparsity 0.4849804092294297\n",
            "before agg client 2 has sparsity 0.4849804092294297\n",
            "Weighted aggregated client weights\n",
            "after broadcasting client has sparsity 0.4264257727470614\n",
            "after broadcasting client has sparsity 0.4264257727470614\n",
            "after broadcasting client has sparsity 0.4264257727470614\n",
            "Broadcasted weights to all clients\n",
            "training client 0 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 8s 12ms/step - loss: 0.3899 - sparse_categorical_accuracy: 0.8824 - val_loss: 0.3071 - val_sparse_categorical_accuracy: 0.9175\n",
            "training client 1 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 8s 14ms/step - loss: 0.3927 - sparse_categorical_accuracy: 0.8826 - val_loss: 0.3652 - val_sparse_categorical_accuracy: 0.8970\n",
            "training client 2 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 7s 13ms/step - loss: 0.3844 - sparse_categorical_accuracy: 0.8828 - val_loss: 0.2386 - val_sparse_categorical_accuracy: 0.9335\n",
            "trained all clients cnn round 1\n",
            "before agg client 0 has sparsity 0.4849804092294297\n",
            "before agg client 1 has sparsity 0.4849804092294297\n",
            "before agg client 2 has sparsity 0.4849804092294297\n",
            "Weighted aggregated client weights\n",
            "after broadcasting client has sparsity 0.46408358728776666\n",
            "after broadcasting client has sparsity 0.46408358728776666\n",
            "after broadcasting client has sparsity 0.46408358728776666\n",
            "Broadcasted weights to all clients\n",
            "training client 0 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 7s 13ms/step - loss: 0.3507 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.2816 - val_sparse_categorical_accuracy: 0.9190\n",
            "training client 1 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 8s 16ms/step - loss: 0.3512 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.3383 - val_sparse_categorical_accuracy: 0.9000\n",
            "training client 2 's cnn\n",
            "begin_step= 0 end_step= 282\n",
            "282/282 [==============================] - 7s 13ms/step - loss: 0.3445 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.2243 - val_sparse_categorical_accuracy: 0.9370\n",
            "trained all clients cnn round 2\n",
            "before agg client 0 has sparsity 0.4849804092294297\n",
            "before agg client 1 has sparsity 0.4849804092294297\n",
            "before agg client 2 has sparsity 0.4849804092294297\n",
            "Weighted aggregated client weights\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3172 - sparse_categorical_accuracy: 0.9082\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3139 - sparse_categorical_accuracy: 0.9087\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3113 - sparse_categorical_accuracy: 0.9087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_k = x_train[:no_sample]\n",
        "y_train_k = y_train[:no_sample]\n",
        "client = Client(smallCNN(), x_train_k, y_train_k)\n",
        "client.local_train(epochs = 3, is_prune = True)\n",
        "client.cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nikIXLJS_NO_",
        "outputId": "62f42ea6-d9f9-4e5f-e359-2cfa16ac0df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "begin_step= 0 end_step= 844\n",
            "Epoch 1/3\n",
            "282/282 [==============================] - 7s 12ms/step - loss: 0.8385 - sparse_categorical_accuracy: 0.7484 - val_loss: 0.3486 - val_sparse_categorical_accuracy: 0.8985\n",
            "Epoch 2/3\n",
            "282/282 [==============================] - 4s 15ms/step - loss: 0.3786 - sparse_categorical_accuracy: 0.8857 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.9150\n",
            "Epoch 3/3\n",
            "282/282 [==============================] - 3s 10ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.2797 - val_sparse_categorical_accuracy: 0.9235\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.3094 - sparse_categorical_accuracy: 0.9068\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30936574935913086, 0.9067999720573425]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script for FedPKDG"
      ],
      "metadata": {
        "id": "R7gwXdOu4HjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initiate 3 clients\n",
        "no_sample = len(x_train) // 3\n",
        "client_list = []\n",
        "for i in range(3):\n",
        "  #partition dataset to mimic private data\n",
        "  x_train_k = x_train[no_sample*i:no_sample*(i+1)]\n",
        "  y_train_k = y_train[no_sample*i:no_sample*(i+1)]\n",
        "  client_list.append(Client(smallCNN(), x_train_k, y_train_k))\n",
        "\n",
        "#initiate 1 server\n",
        "Server = Server(smallCNN(), client_list, comm_freq = 2, algo='FedPKDG')\n",
        "\n",
        "total_rounds = 3\n",
        "for round in range(total_rounds):\n",
        "  target_sparsity = 0.5*(round/total_rounds)\n",
        "  alpha = 0.9*(1-round/total_rounds)\n",
        "  Server.broadcast()\n",
        "  print('>>>>>>>>>Broadcasted weights to all clients')\n",
        "  if round == 0:\n",
        "    Server.local_training(gen_epochs=10,target_sparsity = target_sparsity)\n",
        "    print('>>>>>>>>>trained all clients cnn round', _)\n",
        "    Server.agg_gen()\n",
        "    print('>>>>>>>>>Weighted aggregated client generator')\n",
        "    Server.produce_pseudo_dataset(total_num = 2000)\n",
        "  else:\n",
        "    Server.local_training()\n",
        "    print('>>>>>>>>>trained all clients cnn round', _)\n",
        "    Server.agg_gen()\n",
        "    print('>>>>>>>>>Weighted aggregated client generator')\n",
        "    Server.produce_pseudo_dataset()\n",
        "    print('>>>>>>>>>produced pseudo data')\n",
        "\n",
        "  Server.distill_to_global()\n",
        "  print('>>>>>>>>>Knowledge distilled from clients and updated global weights')\n",
        "\n",
        "Server.broadcast()\n",
        "print('>>>>>>>>>Broadcasted weights to all clients')\n",
        "Server.local_training()\n",
        "print('>>>>>>>>>trained all clients cnn final round')\n",
        "for client in client_list:\n",
        "  print('local models evaluation')\n",
        "  client.cnn.evaluate(x_test, y_test)\n",
        "print('global model evaluation')\n",
        "Server.cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3SZD-W34F8y",
        "outputId": "211b5dfc-f359-42a0-9590-2a2e5918c277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0056595559425337396\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.8455 - sparse_categorical_accuracy: 0.7486 - val_loss: 0.3442 - val_sparse_categorical_accuracy: 0.8985\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.9135\n",
            "after pruning client has sparsity 0.0\n",
            "training client 0 's GEN\n",
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - d_loss: 0.4390 - g_loss: 1.4507\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - d_loss: 0.3727 - g_loss: 1.4628\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.5172 - g_loss: 1.2452\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - d_loss: 0.5640 - g_loss: 1.1373\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.5206 - g_loss: 1.2646\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.4366 - g_loss: 1.4711\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.4206 - g_loss: 1.4833\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.4409 - g_loss: 1.4470\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.3189 - g_loss: 2.0744\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.3403 - g_loss: 1.7905\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0056595559425337396\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.8433 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.4039 - val_sparse_categorical_accuracy: 0.8780\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.3756 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.3629 - val_sparse_categorical_accuracy: 0.8965\n",
            "after pruning client has sparsity 0.0\n",
            "training client 1 's GEN\n",
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - d_loss: 0.4372 - g_loss: 1.4580\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.3986 - g_loss: 1.4277\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.4495 - g_loss: 1.3794\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.5170 - g_loss: 1.2657\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.5179 - g_loss: 1.2836\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.4494 - g_loss: 1.3755\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.4752 - g_loss: 1.3737\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.3927 - g_loss: 1.5437\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.3726 - g_loss: 1.5940\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.3272 - g_loss: 1.8756\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0056595559425337396\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 8ms/step - loss: 0.8349 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.9195\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 8ms/step - loss: 0.3757 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.2304 - val_sparse_categorical_accuracy: 0.9370\n",
            "after pruning client has sparsity 0.0\n",
            "training client 2 's GEN\n",
            "Epoch 1/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - d_loss: 0.5230 - g_loss: 1.2250\n",
            "Epoch 2/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.4075 - g_loss: 1.3094\n",
            "Epoch 3/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.4868 - g_loss: 1.2727\n",
            "Epoch 4/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - d_loss: 0.5023 - g_loss: 1.3208\n",
            "Epoch 5/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.4731 - g_loss: 1.3848\n",
            "Epoch 6/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.4744 - g_loss: 1.3953\n",
            "Epoch 7/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.4691 - g_loss: 1.3807\n",
            "Epoch 8/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.3760 - g_loss: 1.6723\n",
            "Epoch 9/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.3589 - g_loss: 1.7458\n",
            "Epoch 10/10\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.2721 - g_loss: 1.9389\n",
            ">>>>>>>>>trained all clients cnn round 0\n",
            "----getting weighted avg of clients' gen\n",
            ">>>>>>>>>Weighted aggregated client generator\n",
            "Generating 200 fake images of digit 0 ......\n",
            "Generating 200 fake images of digit 1 ......\n",
            "Generating 200 fake images of digit 2 ......\n",
            "Generating 200 fake images of digit 3 ......\n",
            "Generating 200 fake images of digit 4 ......\n",
            "Generating 200 fake images of digit 5 ......\n",
            "Generating 200 fake images of digit 6 ......\n",
            "Generating 200 fake images of digit 7 ......\n",
            "Generating 200 fake images of digit 8 ......\n",
            "Generating 200 fake images of digit 9 ......\n",
            "----getting weighted avg of clients' classifier\n",
            "Epoch 1/3\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "57/57 [==============================] - 3s 11ms/step - sparse_categorical_accuracy: 0.4756 - task_loss: 1.6885 - distillation_loss: 0.3271 - total_loss: 2.1907 - val_sparse_categorical_accuracy: 0.1800\n",
            "Epoch 2/3\n",
            "57/57 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.5506 - task_loss: 1.5625 - distillation_loss: 0.0760 - total_loss: 1.2112 - val_sparse_categorical_accuracy: 0.2000\n",
            "Epoch 3/3\n",
            "57/57 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.5783 - task_loss: 1.4642 - distillation_loss: 0.0361 - total_loss: 1.0085 - val_sparse_categorical_accuracy: 0.1950\n",
            "should print not trainable: False\n",
            "should print trainable: True\n",
            ">>>>>>>>>Knowledge distilled from clients and updated global weights\n",
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.3595 - sparse_categorical_accuracy: 0.8935 - val_loss: 0.2927 - val_sparse_categorical_accuracy: 0.9175\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 8ms/step - loss: 0.3292 - sparse_categorical_accuracy: 0.9016 - val_loss: 0.2831 - val_sparse_categorical_accuracy: 0.9190\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 0 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - d_loss: 0.5827 - g_loss: 1.2034\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.6493 - g_loss: 0.9160\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.3625 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3439 - val_sparse_categorical_accuracy: 0.8955\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.3332 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.3278 - val_sparse_categorical_accuracy: 0.9025\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 1 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - d_loss: 0.5852 - g_loss: 1.2368\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.6701 - g_loss: 0.9061\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 6s 7ms/step - loss: 0.3604 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.2457 - val_sparse_categorical_accuracy: 0.9280\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.2159 - val_sparse_categorical_accuracy: 0.9445\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 2 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - d_loss: 0.5082 - g_loss: 1.7238\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - d_loss: 0.6255 - g_loss: 1.0012\n",
            ">>>>>>>>>trained all clients cnn round 0\n",
            "----getting weighted avg of clients' gen\n",
            ">>>>>>>>>Weighted aggregated client generator\n",
            "Generating 32 fake images of digit 0 ......\n",
            "Generating 32 fake images of digit 1 ......\n",
            "Generating 32 fake images of digit 2 ......\n",
            "Generating 32 fake images of digit 3 ......\n",
            "Generating 32 fake images of digit 4 ......\n",
            "Generating 32 fake images of digit 5 ......\n",
            "Generating 32 fake images of digit 6 ......\n",
            "Generating 32 fake images of digit 7 ......\n",
            "Generating 32 fake images of digit 8 ......\n",
            "Generating 32 fake images of digit 9 ......\n",
            ">>>>>>>>>produced pseudo data\n",
            "----getting weighted avg of clients' classifier\n",
            "Epoch 1/3\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "66/66 [==============================] - 4s 10ms/step - sparse_categorical_accuracy: 0.5536 - task_loss: 1.4903 - distillation_loss: 0.0327 - total_loss: 1.0117 - val_sparse_categorical_accuracy: 0.8190\n",
            "Epoch 2/3\n",
            "66/66 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.5642 - task_loss: 1.4654 - distillation_loss: 0.0301 - total_loss: 0.9875 - val_sparse_categorical_accuracy: 0.8190\n",
            "Epoch 3/3\n",
            "66/66 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.5771 - task_loss: 1.3683 - distillation_loss: 0.0324 - total_loss: 0.9375 - val_sparse_categorical_accuracy: 0.8233\n",
            "should print not trainable: False\n",
            "should print trainable: True\n",
            ">>>>>>>>>Knowledge distilled from clients and updated global weights\n",
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.21462777535916414\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.3350 - sparse_categorical_accuracy: 0.8982 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.9230\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.3137 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.2597 - val_sparse_categorical_accuracy: 0.9245\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 0 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - d_loss: 0.6764 - g_loss: 0.8709\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.6214 - g_loss: 0.9747\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.3158 - val_sparse_categorical_accuracy: 0.9055\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.9087 - val_loss: 0.3198 - val_sparse_categorical_accuracy: 0.9035\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 1 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - d_loss: 0.6975 - g_loss: 0.8660\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.5642 - g_loss: 1.0905\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.21462777535916414\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.3325 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.2119 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.3121 - sparse_categorical_accuracy: 0.9056 - val_loss: 0.2165 - val_sparse_categorical_accuracy: 0.9370\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 2 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - d_loss: 0.6894 - g_loss: 0.8928\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.6661 - g_loss: 0.8846\n",
            ">>>>>>>>>trained all clients cnn round 0\n",
            "----getting weighted avg of clients' gen\n",
            ">>>>>>>>>Weighted aggregated client generator\n",
            "Generating 32 fake images of digit 0 ......\n",
            "Generating 32 fake images of digit 1 ......\n",
            "Generating 32 fake images of digit 2 ......\n",
            "Generating 32 fake images of digit 3 ......\n",
            "Generating 32 fake images of digit 4 ......\n",
            "Generating 32 fake images of digit 5 ......\n",
            "Generating 32 fake images of digit 6 ......\n",
            "Generating 32 fake images of digit 7 ......\n",
            "Generating 32 fake images of digit 8 ......\n",
            "Generating 32 fake images of digit 9 ......\n",
            ">>>>>>>>>produced pseudo data\n",
            "----getting weighted avg of clients' classifier\n",
            "Epoch 1/3\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "75/75 [==============================] - 3s 9ms/step - sparse_categorical_accuracy: 0.5934 - task_loss: 1.3051 - distillation_loss: 0.0308 - total_loss: 0.8938 - val_sparse_categorical_accuracy: 0.8902\n",
            "Epoch 2/3\n",
            "75/75 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.6073 - task_loss: 1.3028 - distillation_loss: 0.0297 - total_loss: 0.8885 - val_sparse_categorical_accuracy: 0.9091\n",
            "Epoch 3/3\n",
            "75/75 [==============================] - 1s 7ms/step - sparse_categorical_accuracy: 0.6120 - task_loss: 1.2663 - distillation_loss: 0.0309 - total_loss: 0.8710 - val_sparse_categorical_accuracy: 0.9091\n",
            "should print not trainable: False\n",
            "should print trainable: True\n",
            ">>>>>>>>>Knowledge distilled from clients and updated global weights\n",
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.2218110579016108\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 6s 7ms/step - loss: 0.3176 - sparse_categorical_accuracy: 0.9063 - val_loss: 0.2605 - val_sparse_categorical_accuracy: 0.9210\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.2979 - sparse_categorical_accuracy: 0.9133 - val_loss: 0.2526 - val_sparse_categorical_accuracy: 0.9270\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 0 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - d_loss: 0.6457 - g_loss: 0.8891\n",
            "Epoch 2/2\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.6243 - g_loss: 0.9664\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.2218110579016108\n",
            "begin_step= 0 end_step= 563\n",
            "Epoch 1/2\n",
            "282/282 [==============================] - 6s 7ms/step - loss: 0.3202 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.9065\n",
            "Epoch 2/2\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.3014 - sparse_categorical_accuracy: 0.9109 - val_loss: 0.2967 - val_sparse_categorical_accuracy: 0.9070\n",
            "after pruning client has sparsity 0.29799738789725727\n",
            "training client 1 's GEN\n",
            "Epoch 1/2\n",
            "\u001b[1m 33/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - d_loss: 0.7274 - g_loss: 0.8622"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "my58ZMvu-l3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## communication rounds"
      ],
      "metadata": {
        "id": "FLINY9_0aSJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. aggregate only after convergence"
      ],
      "metadata": {
        "id": "s-aTo-yqDfA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initiate 3 clients\n",
        "no_sample = len(x_train) // 3\n",
        "client_list = []\n",
        "for i in range(3):\n",
        "  #partition dataset to mimic private data\n",
        "  x_train_k = x_train[no_sample*i:no_sample*(i+1)]\n",
        "  y_train_k = y_train[no_sample*i:no_sample*(i+1)]\n",
        "  client_list.append(Client(smallCNN(), x_train_k, y_train_k))\n",
        "\n",
        "#initiate 1 server\n",
        "Server = Server(smallCNN(), client_list, comm_freq = 5, algo='FedPKDG')\n",
        "\n",
        "total_rounds = 3\n",
        "for round in range(total_rounds):\n",
        "  target_sparsity = 0.5*(round/total_rounds)\n",
        "  alpha = 0.9*(1-round/total_rounds)\n",
        "  Server.broadcast()\n",
        "  print('>>>>>>>>>Broadcasted weights to all clients')\n",
        "  if round == 0:\n",
        "    Server.local_training(cnn_epochs = 10, gen_epochs=20, target_sparsity = target_sparsity, fine_tune_epochs=3)\n",
        "    print('>>>>>>>>>trained all clients cnn round', _)\n",
        "    Server.agg_gen()\n",
        "    print('>>>>>>>>>Weighted aggregated client generator')\n",
        "    Server.produce_pseudo_dataset(total_num = 2000)\n",
        "  else:\n",
        "    Server.local_training(target_sparsity = target_sparsity, fine_tune_epochs=1)\n",
        "    print('>>>>>>>>>trained all clients cnn round', _)\n",
        "    Server.agg_gen()\n",
        "    print('>>>>>>>>>Weighted aggregated client generator')\n",
        "    Server.produce_pseudo_dataset()\n",
        "    print('>>>>>>>>>produced pseudo data')\n",
        "\n",
        "  Server.distill_to_global()\n",
        "  print('>>>>>>>>>Knowledge distilled from clients and updated global weights')\n",
        "\n",
        "Server.broadcast()\n",
        "print('>>>>>>>>>Broadcasted weights to all clients')\n",
        "Server.local_training()\n",
        "print('>>>>>>>>>trained all clients cnn final round')\n",
        "for client in client_list:\n",
        "  print('local models evaluation')\n",
        "  client.cnn.evaluate(x_test, y_test)\n",
        "print('global model evaluation')\n",
        "Server.cnn.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgsmScgfaWqp",
        "outputId": "7a45ccb9-9d95-4720-b693-13932272172b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0056595559425337396\n",
            "begin_step= 843 end_step= 2811\n",
            "Epoch 1/10\n",
            "282/282 [==============================] - 36s 11ms/step - loss: 0.7789 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.3392 - val_sparse_categorical_accuracy: 0.9070\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.3341 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.2573 - val_sparse_categorical_accuracy: 0.9240\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 2s 9ms/step - loss: 0.2639 - sparse_categorical_accuracy: 0.9198 - val_loss: 0.2100 - val_sparse_categorical_accuracy: 0.9400\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9357 - val_loss: 0.1741 - val_sparse_categorical_accuracy: 0.9485\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1893 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.1610 - val_sparse_categorical_accuracy: 0.9510\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.1410 - val_sparse_categorical_accuracy: 0.9575\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.1342 - val_sparse_categorical_accuracy: 0.9585\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 2s 7ms/step - loss: 0.1344 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9605\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.1172 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1130 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9690\n",
            "after pruning client has sparsity 0.0\n",
            "training client 0 's GEN\n",
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - d_loss: 0.4812 - g_loss: 1.4132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 41ms/step - d_loss: 0.4811 - g_loss: 1.4137\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.3996 - g_loss: 1.3748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.3995 - g_loss: 1.3752\n",
            "Epoch 3/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.4420 - g_loss: 1.3872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.4421 - g_loss: 1.3870\n",
            "Epoch 4/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.4617 - g_loss: 1.4091"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.4618 - g_loss: 1.4089\n",
            "Epoch 5/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.5127 - g_loss: 1.3083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.5126 - g_loss: 1.3084\n",
            "Epoch 6/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.5387 - g_loss: 1.2607"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.5385 - g_loss: 1.2612\n",
            "Epoch 7/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.5055 - g_loss: 1.3490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.5053 - g_loss: 1.3485\n",
            "Epoch 8/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.4729 - g_loss: 1.3529"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - d_loss: 0.4729 - g_loss: 1.3526\n",
            "Epoch 9/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.3955 - g_loss: 1.5037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - d_loss: 0.3956 - g_loss: 1.5040\n",
            "Epoch 10/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.3204 - g_loss: 1.8348"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.3207 - g_loss: 1.8340\n",
            "Epoch 11/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.2775 - g_loss: 2.0268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.2775 - g_loss: 2.0267\n",
            "Epoch 12/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.2387 - g_loss: 2.1339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.2387 - g_loss: 2.1341\n",
            "Epoch 13/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.2090 - g_loss: 2.3779"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - d_loss: 0.2089 - g_loss: 2.3780\n",
            "Epoch 14/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.1867 - g_loss: 2.4914"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.1867 - g_loss: 2.4912\n",
            "Epoch 15/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.2025 - g_loss: 2.3824"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.2032 - g_loss: 2.3803\n",
            "Epoch 16/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.5698 - g_loss: 1.1995"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.5698 - g_loss: 1.1995\n",
            "Epoch 17/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.5611 - g_loss: 1.3507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.5610 - g_loss: 1.3510\n",
            "Epoch 18/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.5942 - g_loss: 1.2076"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.5944 - g_loss: 1.2066\n",
            "Epoch 19/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.5925 - g_loss: 1.0748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.5926 - g_loss: 1.0748\n",
            "Epoch 20/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.5920 - g_loss: 1.1466"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.5922 - g_loss: 1.1458\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0056595559425337396\n",
            "begin_step= 843 end_step= 2811\n",
            "Epoch 1/10\n",
            "282/282 [==============================] - 6s 7ms/step - loss: 0.7666 - sparse_categorical_accuracy: 0.7703 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8875\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.3289 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.9035\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.2586 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.2437 - val_sparse_categorical_accuracy: 0.9260\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9361 - val_loss: 0.2143 - val_sparse_categorical_accuracy: 0.9350\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1862 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.1943 - val_sparse_categorical_accuracy: 0.9405\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 2s 8ms/step - loss: 0.1677 - sparse_categorical_accuracy: 0.9470 - val_loss: 0.1782 - val_sparse_categorical_accuracy: 0.9435\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.1706 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9565 - val_loss: 0.1540 - val_sparse_categorical_accuracy: 0.9495\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.1544 - val_sparse_categorical_accuracy: 0.9515\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9616 - val_loss: 0.1471 - val_sparse_categorical_accuracy: 0.9545\n",
            "after pruning client has sparsity 0.0\n",
            "training client 1 's GEN\n",
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - d_loss: 0.4729 - g_loss: 1.3425"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - d_loss: 0.4729 - g_loss: 1.3428\n",
            "Epoch 2/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3850 - g_loss: 1.4367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.3852 - g_loss: 1.4370\n",
            "Epoch 3/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4129 - g_loss: 1.4642"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.4128 - g_loss: 1.4647\n",
            "Epoch 4/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.4144 - g_loss: 1.5888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.4146 - g_loss: 1.5883\n",
            "Epoch 5/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4891 - g_loss: 1.3921"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.4890 - g_loss: 1.3926\n",
            "Epoch 6/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4830 - g_loss: 1.4516"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.4830 - g_loss: 1.4514\n",
            "Epoch 7/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4379 - g_loss: 1.4299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.4379 - g_loss: 1.4302\n",
            "Epoch 8/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4284 - g_loss: 1.5224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.4283 - g_loss: 1.5226\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3929 - g_loss: 1.6799"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.3929 - g_loss: 1.6800\n",
            "Epoch 10/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3181 - g_loss: 1.9139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.3181 - g_loss: 1.9139\n",
            "Epoch 11/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.3009 - g_loss: 1.9451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.3007 - g_loss: 1.9456\n",
            "Epoch 12/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.2559 - g_loss: 2.1470"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.2558 - g_loss: 2.1472\n",
            "Epoch 13/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.2048 - g_loss: 2.3015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.2048 - g_loss: 2.3016\n",
            "Epoch 14/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.1729 - g_loss: 2.4932"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.1729 - g_loss: 2.4933\n",
            "Epoch 15/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.1488 - g_loss: 2.7003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.1488 - g_loss: 2.7003\n",
            "Epoch 16/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.1454 - g_loss: 2.7365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.1456 - g_loss: 2.7356\n",
            "Epoch 17/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.5243 - g_loss: 1.5501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - d_loss: 0.5248 - g_loss: 1.5485\n",
            "Epoch 18/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.5824 - g_loss: 1.2091"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.5824 - g_loss: 1.2105\n",
            "Epoch 19/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4387 - g_loss: 1.9382"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.4389 - g_loss: 1.9369\n",
            "Epoch 20/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6448 - g_loss: 1.0119"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6447 - g_loss: 1.0119\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0056595559425337396\n",
            "begin_step= 843 end_step= 2811\n",
            "Epoch 1/10\n",
            "282/282 [==============================] - 6s 7ms/step - loss: 0.7764 - sparse_categorical_accuracy: 0.7644 - val_loss: 0.2478 - val_sparse_categorical_accuracy: 0.9360\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.3272 - sparse_categorical_accuracy: 0.9022 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9520\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.2526 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9585\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.2097 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.1362 - val_sparse_categorical_accuracy: 0.9655\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1827 - sparse_categorical_accuracy: 0.9449 - val_loss: 0.1239 - val_sparse_categorical_accuracy: 0.9675\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9502 - val_loss: 0.1087 - val_sparse_categorical_accuracy: 0.9745\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 2s 8ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9710\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.0879 - val_sparse_categorical_accuracy: 0.9805\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9775\n",
            "after pruning client has sparsity 0.0\n",
            "training client 2 's GEN\n",
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - d_loss: 0.5103 - g_loss: 1.2371"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - d_loss: 0.5101 - g_loss: 1.2374\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3552 - g_loss: 1.6235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.3552 - g_loss: 1.6239\n",
            "Epoch 3/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.3924 - g_loss: 1.5021"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.3925 - g_loss: 1.5017\n",
            "Epoch 4/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4455 - g_loss: 1.4985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.4454 - g_loss: 1.4985\n",
            "Epoch 5/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4779 - g_loss: 1.4446"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.4778 - g_loss: 1.4447\n",
            "Epoch 6/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4922 - g_loss: 1.3052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.4921 - g_loss: 1.3056\n",
            "Epoch 7/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.4310 - g_loss: 1.4833"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.4310 - g_loss: 1.4834\n",
            "Epoch 8/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3885 - g_loss: 1.5541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.3884 - g_loss: 1.5544\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3699 - g_loss: 1.6929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.3698 - g_loss: 1.6932\n",
            "Epoch 10/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.3100 - g_loss: 1.9655"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.3100 - g_loss: 1.9648\n",
            "Epoch 11/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.2799 - g_loss: 1.9331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.2800 - g_loss: 1.9332\n",
            "Epoch 12/20\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.5286 - g_loss: 1.4303"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.5292 - g_loss: 1.4287\n",
            "Epoch 13/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6377 - g_loss: 0.9263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6376 - g_loss: 0.9265\n",
            "Epoch 14/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6291 - g_loss: 0.9640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.6291 - g_loss: 0.9640\n",
            "Epoch 15/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6287 - g_loss: 0.9350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6287 - g_loss: 0.9350\n",
            "Epoch 16/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6304 - g_loss: 0.9277"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6304 - g_loss: 0.9279\n",
            "Epoch 17/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6452 - g_loss: 0.8986"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6451 - g_loss: 0.8986\n",
            "Epoch 18/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6390 - g_loss: 0.9124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6391 - g_loss: 0.9123\n",
            "Epoch 19/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6435 - g_loss: 0.8747"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6435 - g_loss: 0.8746\n",
            "Epoch 20/20\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6514 - g_loss: 0.8517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6514 - g_loss: 0.8517\n",
            ">>>>>>>>>trained all clients cnn round \n",
            "----getting weighted avg of clients' gen\n",
            ">>>>>>>>>Weighted aggregated client generator\n",
            "Generating 100 fake images of digit 0 ......\n",
            "Generating 100 fake images of digit 1 ......\n",
            "Generating 100 fake images of digit 2 ......\n",
            "Generating 100 fake images of digit 3 ......\n",
            "Generating 100 fake images of digit 4 ......\n",
            "Generating 100 fake images of digit 5 ......\n",
            "Generating 100 fake images of digit 6 ......\n",
            "Generating 100 fake images of digit 7 ......\n",
            "Generating 100 fake images of digit 8 ......\n",
            "Generating 100 fake images of digit 9 ......\n",
            "Augmented dataset shape: (1000, 28, 28, 1), (1000,)\n",
            "Added (2000,) data points to the public dataset\n",
            "----getting weighted avg of clients' classifier\n",
            "Epoch 1/3\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "57/57 [==============================] - 7s 14ms/step - sparse_categorical_accuracy: 0.3356 - task_loss: 2.0073 - distillation_loss: 0.2273 - total_loss: 2.0226 - val_sparse_categorical_accuracy: 0.1400\n",
            "Epoch 2/3\n",
            "57/57 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.4233 - task_loss: 1.8180 - distillation_loss: 0.1109 - total_loss: 1.4901 - val_sparse_categorical_accuracy: 0.1650\n",
            "Epoch 3/3\n",
            "57/57 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.4572 - task_loss: 1.7711 - distillation_loss: 0.0686 - total_loss: 1.3096 - val_sparse_categorical_accuracy: 0.1800\n",
            "should print not trainable: False\n",
            "should print trainable: True\n",
            ">>>>>>>>>Knowledge distilled from clients and updated global weights\n",
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 281 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 7s 11ms/step - loss: 0.2949 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.1731 - val_sparse_categorical_accuracy: 0.9510\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1911 - sparse_categorical_accuracy: 0.9424 - val_loss: 0.1512 - val_sparse_categorical_accuracy: 0.9560\n",
            "Epoch 3/5\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.1368 - val_sparse_categorical_accuracy: 0.9575\n",
            "Epoch 4/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.1337 - val_sparse_categorical_accuracy: 0.9600\n",
            "Epoch 5/5\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1292 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1227 - val_sparse_categorical_accuracy: 0.9630\n",
            "after pruning client has sparsity 0.16565084893339138\n",
            "training client 0 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - d_loss: 0.3988 - g_loss: 1.5576"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - d_loss: 0.3990 - g_loss: 1.5573\n",
            "Epoch 2/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.5893 - g_loss: 1.2672"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - d_loss: 0.5894 - g_loss: 1.2668\n",
            "Epoch 3/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6031 - g_loss: 1.0798"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - d_loss: 0.6032 - g_loss: 1.0798\n",
            "Epoch 4/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6281 - g_loss: 1.0282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.6282 - g_loss: 1.0277\n",
            "Epoch 5/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6483 - g_loss: 1.0499"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.6483 - g_loss: 1.0498\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 281 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 6s 9ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9290\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1877 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1871 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 3/5\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1593 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.1674 - val_sparse_categorical_accuracy: 0.9490\n",
            "Epoch 4/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1415 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9535\n",
            "Epoch 5/5\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.1399 - val_sparse_categorical_accuracy: 0.9520\n",
            "after pruning client has sparsity 0.16565084893339138\n",
            "training client 1 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - d_loss: 0.3855 - g_loss: 1.8284"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - d_loss: 0.3857 - g_loss: 1.8278\n",
            "Epoch 2/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.5954 - g_loss: 1.1981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - d_loss: 0.5957 - g_loss: 1.1977\n",
            "Epoch 3/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6488 - g_loss: 1.0304"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.6489 - g_loss: 1.0306\n",
            "Epoch 4/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6898 - g_loss: 0.9465"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - d_loss: 0.6897 - g_loss: 0.9465\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6757 - g_loss: 0.9165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - d_loss: 0.6757 - g_loss: 0.9165\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 281 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 5s 7ms/step - loss: 0.2865 - sparse_categorical_accuracy: 0.9149 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9620\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1885 - sparse_categorical_accuracy: 0.9436 - val_loss: 0.1202 - val_sparse_categorical_accuracy: 0.9705\n",
            "Epoch 3/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9710\n",
            "Epoch 4/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.1424 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 5/5\n",
            "282/282 [==============================] - 3s 9ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9602 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9770\n",
            "after pruning client has sparsity 0.16565084893339138\n",
            "training client 2 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - d_loss: 0.4091 - g_loss: 1.3611"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - d_loss: 0.4093 - g_loss: 1.3608\n",
            "Epoch 2/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.4606 - g_loss: 1.4149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.4607 - g_loss: 1.4146\n",
            "Epoch 3/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.5835 - g_loss: 1.0783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - d_loss: 0.5835 - g_loss: 1.0781\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.5940 - g_loss: 1.0367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.5941 - g_loss: 1.0366\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6387 - g_loss: 0.9268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6387 - g_loss: 0.9268\n",
            ">>>>>>>>>trained all clients cnn round \n",
            "----getting weighted avg of clients' gen\n",
            ">>>>>>>>>Weighted aggregated client generator\n",
            "Generating 16 fake images of digit 0 ......\n",
            "Generating 16 fake images of digit 1 ......\n",
            "Generating 16 fake images of digit 2 ......\n",
            "Generating 16 fake images of digit 3 ......\n",
            "Generating 16 fake images of digit 4 ......\n",
            "Generating 16 fake images of digit 5 ......\n",
            "Generating 16 fake images of digit 6 ......\n",
            "Generating 16 fake images of digit 7 ......\n",
            "Generating 16 fake images of digit 8 ......\n",
            "Generating 16 fake images of digit 9 ......\n",
            "Augmented dataset shape: (160, 28, 28, 1), (160,)\n",
            "Added (320,) data points to the public dataset\n",
            ">>>>>>>>>produced pseudo data\n",
            "----getting weighted avg of clients' classifier\n",
            "Epoch 1/3\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "66/66 [==============================] - 4s 9ms/step - sparse_categorical_accuracy: 0.1058 - task_loss: nan - distillation_loss: nan - total_loss: nan - val_sparse_categorical_accuracy: 0.1379\n",
            "Epoch 2/3\n",
            "66/66 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.1015 - task_loss: nan - distillation_loss: nan - total_loss: nan - val_sparse_categorical_accuracy: 0.1379\n",
            "Epoch 3/3\n",
            "66/66 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.1015 - task_loss: nan - distillation_loss: nan - total_loss: nan - val_sparse_categorical_accuracy: 0.1379\n",
            "should print not trainable: False\n",
            "should print trainable: True\n",
            ">>>>>>>>>Knowledge distilled from clients and updated global weights\n",
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0805398345668263\n",
            "begin_step= 281 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 6s 10ms/step - loss: nan - sparse_categorical_accuracy: 0.0991 - val_loss: nan - val_sparse_categorical_accuracy: 0.1055\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 3s 10ms/step - loss: nan - sparse_categorical_accuracy: 0.0991 - val_loss: nan - val_sparse_categorical_accuracy: 0.1055\n",
            "Epoch 2: early stopping\n",
            "after pruning client has sparsity 0.0\n",
            "training client 0 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - d_loss: 0.6677 - g_loss: 0.9455"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - d_loss: 0.6677 - g_loss: 0.9456\n",
            "Epoch 2/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6673 - g_loss: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - d_loss: 0.6673 - g_loss: 0.9437\n",
            "Epoch 3/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - d_loss: 0.6600 - g_loss: 0.9040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - d_loss: 0.6601 - g_loss: 0.9039\n",
            "Epoch 4/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6790 - g_loss: 0.8211"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6790 - g_loss: 0.8212\n",
            "Epoch 5/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6791 - g_loss: 0.8734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6792 - g_loss: 0.8731\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0805398345668263\n",
            "begin_step= 281 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 6s 7ms/step - loss: nan - sparse_categorical_accuracy: 0.0958 - val_loss: nan - val_sparse_categorical_accuracy: 0.1030\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: nan - sparse_categorical_accuracy: 0.0958 - val_loss: nan - val_sparse_categorical_accuracy: 0.1030\n",
            "Epoch 2: early stopping\n",
            "after pruning client has sparsity 0.0\n",
            "training client 1 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - d_loss: 0.7191 - g_loss: 0.8242"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - d_loss: 0.7191 - g_loss: 0.8242\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6885 - g_loss: 0.8694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - d_loss: 0.6885 - g_loss: 0.8693\n",
            "Epoch 3/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6968 - g_loss: 0.8453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6969 - g_loss: 0.8450\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.7015 - g_loss: 0.7686"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.7015 - g_loss: 0.7686\n",
            "Epoch 5/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6942 - g_loss: 0.7963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.6942 - g_loss: 0.7961\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0805398345668263\n",
            "begin_step= 281 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 6s 9ms/step - loss: nan - sparse_categorical_accuracy: 0.1003 - val_loss: nan - val_sparse_categorical_accuracy: 0.0970\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: nan - sparse_categorical_accuracy: 0.1003 - val_loss: nan - val_sparse_categorical_accuracy: 0.0970\n",
            "Epoch 2: early stopping\n",
            "after pruning client has sparsity 0.0\n",
            "training client 2 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - d_loss: 0.6348 - g_loss: 0.9040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - d_loss: 0.6348 - g_loss: 0.9042\n",
            "Epoch 2/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6099 - g_loss: 1.0050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - d_loss: 0.6100 - g_loss: 1.0046\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6529 - g_loss: 0.8790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.6529 - g_loss: 0.8789\n",
            "Epoch 4/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6728 - g_loss: 0.8340"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.6728 - g_loss: 0.8340\n",
            "Epoch 5/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - d_loss: 0.6664 - g_loss: 0.8232"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - d_loss: 0.6664 - g_loss: 0.8232\n",
            ">>>>>>>>>trained all clients cnn round \n",
            "----getting weighted avg of clients' gen\n",
            ">>>>>>>>>Weighted aggregated client generator\n",
            "Generating 16 fake images of digit 0 ......\n",
            "Generating 16 fake images of digit 1 ......\n",
            "Generating 16 fake images of digit 2 ......\n",
            "Generating 16 fake images of digit 3 ......\n",
            "Generating 16 fake images of digit 4 ......\n",
            "Generating 16 fake images of digit 5 ......\n",
            "Generating 16 fake images of digit 6 ......\n",
            "Generating 16 fake images of digit 7 ......\n",
            "Generating 16 fake images of digit 8 ......\n",
            "Generating 16 fake images of digit 9 ......\n",
            "Augmented dataset shape: (160, 28, 28, 1), (160,)\n",
            "Added (320,) data points to the public dataset\n",
            ">>>>>>>>>produced pseudo data\n",
            "----getting weighted avg of clients' classifier\n",
            "Epoch 1/3\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting 1 client logits\n",
            "----getting aggregate client logits Tensor(\"add_1:0\", shape=(None, 10), dtype=float32)\n",
            "75/75 [==============================] - 3s 8ms/step - sparse_categorical_accuracy: 0.1094 - task_loss: nan - distillation_loss: nan - total_loss: nan - val_sparse_categorical_accuracy: 0.1136\n",
            "Epoch 2/3\n",
            "75/75 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.1094 - task_loss: nan - distillation_loss: nan - total_loss: nan - val_sparse_categorical_accuracy: 0.1136\n",
            "Epoch 3/3\n",
            "75/75 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.1094 - task_loss: nan - distillation_loss: nan - total_loss: nan - val_sparse_categorical_accuracy: 0.1136\n",
            "should print not trainable: False\n",
            "should print trainable: True\n",
            ">>>>>>>>>Knowledge distilled from clients and updated global weights\n",
            ">>>>>>>>>Broadcasted weights to all clients\n",
            "training client 0 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 0 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 5s 8ms/step - loss: nan - sparse_categorical_accuracy: 0.0991 - val_loss: nan - val_sparse_categorical_accuracy: 0.1055\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 8ms/step - loss: nan - sparse_categorical_accuracy: 0.0991 - val_loss: nan - val_sparse_categorical_accuracy: 0.1055\n",
            "Epoch 2: early stopping\n",
            "after pruning client has sparsity 0.0\n",
            "training client 0 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - d_loss: 0.7017 - g_loss: 0.8098"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - d_loss: 0.7016 - g_loss: 0.8098\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6923 - g_loss: 0.7803"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.6923 - g_loss: 0.7804\n",
            "Epoch 3/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6777 - g_loss: 0.8132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.6778 - g_loss: 0.8131\n",
            "Epoch 4/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - d_loss: 0.6946 - g_loss: 0.7625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - d_loss: 0.6946 - g_loss: 0.7626\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6909 - g_loss: 0.7654"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - d_loss: 0.6908 - g_loss: 0.7654\n",
            "training client 1 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 0 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 5s 7ms/step - loss: nan - sparse_categorical_accuracy: 0.0958 - val_loss: nan - val_sparse_categorical_accuracy: 0.1030\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 6ms/step - loss: nan - sparse_categorical_accuracy: 0.0958 - val_loss: nan - val_sparse_categorical_accuracy: 0.1030\n",
            "Epoch 2: early stopping\n",
            "after pruning client has sparsity 0.0\n",
            "training client 1 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - d_loss: 0.6997 - g_loss: 0.7709"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - d_loss: 0.6997 - g_loss: 0.7709\n",
            "Epoch 2/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6965 - g_loss: 0.7841"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6965 - g_loss: 0.7841\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.7035 - g_loss: 0.7575"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.7035 - g_loss: 0.7575\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6900 - g_loss: 0.7497"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6900 - g_loss: 0.7497\n",
            "Epoch 5/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6946 - g_loss: 0.7574"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6947 - g_loss: 0.7572\n",
            "training client 2 's CNN\n",
            "from gloabl - before pruning client has sparsity 0.0\n",
            "begin_step= 0 end_step= 1406\n",
            "Epoch 1/5\n",
            "282/282 [==============================] - 6s 8ms/step - loss: nan - sparse_categorical_accuracy: 0.1003 - val_loss: nan - val_sparse_categorical_accuracy: 0.0970\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 2s 9ms/step - loss: nan - sparse_categorical_accuracy: 0.1003 - val_loss: nan - val_sparse_categorical_accuracy: 0.0970\n",
            "Epoch 2: early stopping\n",
            "after pruning client has sparsity 0.0\n",
            "training client 2 's GEN\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - d_loss: 0.6735 - g_loss: 0.8152"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - d_loss: 0.6735 - g_loss: 0.8153\n",
            "Epoch 2/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - d_loss: 0.6571 - g_loss: 0.8892"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - d_loss: 0.6572 - g_loss: 0.8887\n",
            "Epoch 3/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6740 - g_loss: 0.8108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6739 - g_loss: 0.8109\n",
            "Epoch 4/5\n",
            "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6651 - g_loss: 0.8238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - d_loss: 0.6650 - g_loss: 0.8240\n",
            "Epoch 5/5\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - d_loss: 0.6799 - g_loss: 0.7900"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: d_loss,g_loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - d_loss: 0.6799 - g_loss: 0.7900\n",
            ">>>>>>>>>trained all clients cnn final round\n",
            "local models evaluation\n",
            "313/313 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0980\n",
            "local models evaluation\n",
            "313/313 [==============================] - 1s 2ms/step - loss: nan - sparse_categorical_accuracy: 0.0980\n",
            "local models evaluation\n",
            "313/313 [==============================] - 1s 3ms/step - loss: nan - sparse_categorical_accuracy: 0.0980\n",
            "global model evaluation\n",
            "313/313 [==============================] - 2s 3ms/step - loss: nan - sparse_categorical_accuracy: 0.0984\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.09840217977762222]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(10):\n",
        "  pos = idx*100+20\n",
        "  img = Server.x_public[pos]\n",
        "  label = Server.y_public[pos]\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.show()\n",
        "  print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M-RxacJ7IKy5",
        "outputId": "389dc0f0-2dc9-4e1d-a3d4-060a1d83416a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjNElEQVR4nO3df2xV9f3H8ddtaS+ltLeU0h9XWiiooCA1MuiYyhdHA3SJESWLv5aAMRhZMUPmNCwq6pZ0w8SZGab/bDAT8VciEI1jUZCiG7CAMEbcOoqdLdAWKPTettAf9J7vH4RuVyj08+H2fm7L85HchPaeV8+np+f2xe299319nud5AgAgzpJcLwAAcG2igAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4Mcz1Ar4tEono2LFjysjIkM/nc70cAIAhz/PU2tqqYDCopKS+7+ckXAEdO3ZMhYWFrpcBALhK9fX1Gjt2bJ/XJ1wBZWRkSJImT56s5OTkfueOHDlivK/Ozk7jjCSre2apqanGmcv9zyGWuru7rXI264tEIsaZ4cOHG2dMzp3/lZOTY5yxWV9BQYFxxkZ6erpV7vTp08aZ5uZm40xTU5NxJhwOG2c6OjqMM5LU09MTl0w82dxus7OzjbaPRCI6depU7+/zvgxYAa1du1Yvv/yyGhsbVVJSotdee00zZ868Yu7CL/fk5GSjXyI2pWD7J7547cvmRLEZ7TcUj4NtedsU17Bh5jejlJQU44wNm//4SHbrszkONj+noXhbT/Tbre3t6Ur7GpD/Yr/77rtauXKlVq9erS+//FIlJSWaP3++jh8/PhC7AwAMQgNSQK+88oqWLl2qRx55RDfffLPeeOMNjRgxQn/4wx8GYncAgEEo5gXU1dWlvXv3qqys7L87SUpSWVmZdu7cedH2nZ2dCofDURcAwNAX8wI6efKkenp6lJeXF/X5vLw8NTY2XrR9ZWWlAoFA74VnwAHAtcH5C1FXrVqlUCjUe6mvr3e9JABAHMT8WXA5OTlKTk6+6OmVTU1Nys/Pv2h7v98vv98f62UAABJczO8Bpaamavr06dq6dWvv5yKRiLZu3apZs2bFencAgEFqQF4HtHLlSi1evFjf+c53NHPmTL366qtqb2/XI488MhC7AwAMQgNSQPfff79OnDih559/Xo2Njbr11lu1ZcuWi56YAAC4dvk8m5fgDqBwOKxAIKD09HSjV+yePXvWeF/xHJkRr8Gq8RrfI8XvFdU2r7C3nQBgM7rmSuNGLsV0tIkU35+tzSieEydOGGdaWlqMMzajoxLs19ygYzohxPM8RSIRhUIhZWZm9rmd82fBAQCuTRQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwYkCmYcdCV1eX0bDLeA4WHWpsB6WaDiiU7AZq2gwItclIUjAYNM6MGTPGOGPz1vM257jNUFFJamtrM87YnA82GCwaf5FIxGj7/v6MuAcEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJxJ2GjbsJkcPG2b+I01JSTHOSJLf7zfOpKWlGWfGjx9vnCkoKDDOSNLs2bONMzk5OcaZoqIi40w4HDbOHDlyxDgjSSNHjjTOfP7558aZUChknOnq6jLO4OoM1ARy7gEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMJO4w0OTlZPp+v39ubbHvBQA3Yi5Xk5GTjzPDhw40zGRkZxhlJysvLM85cd911xpkpU6YYZyZPnmyckaRbb73VOGMzWDQrK8s4c+bMGeNMU1OTcUaS8vPzjTPHjx83ztgMWO3s7DTO9PT0GGcw8LgHBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOJOww0p6eHqMBo4k+WDReUlNTjTPZ2dlW+5o+fbpx5uabbzbOzJw50zhjM0xTshuwmpaWZpyxOV/9fr9xZvz48cYZSUpJSTHO2Axy/fvf/26ciUQixhkkJu4BAQCcoIAAAE7EvIBeeOEF+Xy+qIvte7MAAIauAXkMaMqUKfr000//u5NhCftQEwDAkQFphmHDhlk/CAwAuDYMyGNAhw4dUjAY1IQJE/Twww+rrq6uz207OzsVDoejLgCAoS/mBVRaWqr169dry5Ytev3111VbW6s777xTra2tl9y+srJSgUCg91JYWBjrJQEAElDMC6i8vFw//OEPNW3aNM2fP18ff/yxWlpa9N57711y+1WrVikUCvVe6uvrY70kAEACGvBnB2RlZenGG29UTU3NJa/3+/1WL7ADAAxuA/46oLa2Nh0+fFgFBQUDvSsAwCAS8wJ66qmnVFVVpf/85z/661//qnvvvVfJycl68MEHY70rAMAgFvM/wR05ckQPPvigmpubNWbMGN1xxx3atWuXxowZE+tdAQAGsZgX0DvvvBOTrxOJRIyGkQ5FNt+/zWDMoqIi44wkq2cs2gzHzMnJMc4MHz7cOCNJHR0dxpmjR48aZ7q7u40zo0aNMs7YnA+S3XFIT083ztj+nDA0MAsOAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJwY8Deks+V5nuslOJeSkmKcGTFihHHGdlJ5bm6ucSY5Odk4U1dXZ5zp6uoyzkhSc3NzXDI2Q0Lz8/ONMzbDXyVZvUlkRkaGcWbkyJHGGZtz6Ny5c8YZDDzuAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMCJhJ2G7fP55PP5XC8jZpKSzLveZupvZmamcSY9Pd04I9lNdD59+rRxpra21jjz9ddfG2ck6cyZM8YZm+/JZrJ1amqqcaawsNA4I9mdezaTt6dMmWKc+fe//22caW1tNc5g4HEPCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcSNhhpJ7nuV5CTEUikbhkenp6jDPt7e3GGUn66quvjDMnTpwwzhw9etQ4U19fb5yRpM7OTuPMsGHmN6O2tjbjzOjRo40z1113nXFGkrq7u40zoVDIOHP27FnjjM1gX1wd08HQ/f39zU8SAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJxI2GGkkM6dO2ecsRlyaTMgVLJbX1NTk3GmsbHRONPa2mqciafk5OS4ZGyGq0p2Q0JtBpjanK82+8HVMR0A63lev4Ypcw8IAOAEBQQAcMK4gHbs2KG7775bwWBQPp9PmzZtirre8zw9//zzKigoUFpamsrKynTo0KFYrRcAMEQYF1B7e7tKSkq0du3aS16/Zs0a/fa3v9Ubb7yh3bt3Kz09XfPnz1dHR8dVLxYAMHQYPwmhvLxc5eXll7zO8zy9+uqrevbZZ3XPPfdIkt58803l5eVp06ZNeuCBB65utQCAISOmjwHV1taqsbFRZWVlvZ8LBAIqLS3Vzp07L5np7OxUOByOugAAhr6YFtCFp8vm5eVFfT4vL6/Pp9JWVlYqEAj0XgoLC2O5JABAgnL+LLhVq1YpFAr1Xurr610vCQAQBzEtoPz8fEkXv9iwqamp97pv8/v9yszMjLoAAIa+mBZQcXGx8vPztXXr1t7PhcNh7d69W7NmzYrlrgAAg5zxs+Da2tpUU1PT+3Ftba3279+v7OxsFRUVacWKFfrlL3+pG264QcXFxXruuecUDAa1cOHCWK4bADDIGRfQnj17dNddd/V+vHLlSknS4sWLtX79ej399NNqb2/XY489ppaWFt1xxx3asmWLhg8fHrtVAwAGPeMCmjNnjjzP6/N6n8+nl156SS+99NJVLSwSicjn813V10gklztmfenp6THO2Ax3tMlIdutrbm42zoRCIeNMV1eXcUaShg0zn88br8GiNpnU1FTjjGR3vtr8nE6dOmWcsVkbro7p7cLzvH7dBp0/Cw4AcG2igAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACfPRv3GSlJRkNA3bZjJzootEInHZj+3U8ezsbONMa2urcSYQCBhnbCd827xtSFpamnEmLy/PODNmzBjjTG5urnFGsptsbXMcbM4hv99vnLGdjj4Uf6/YML1dMA0bAJDQKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEwg4jHWpsBn4mJycbZ1JSUowzNsMdJbvBnTYDNW3YDp8cOXKkcWb06NHGmcLCQuPMhAkTjDP5+fnGGcnuZ/vVV1/FZT+ZmZnGmTNnzhhnJLuBwJ7nWe0rXmx+r5gOBI5EIgqHw1fcjntAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEwg4jHTZsmNEAz3gODbQZLGozJDQ9Pd04M3bsWOPMpEmTjDOSNH78eONMQ0ODcSY1NdU4c+7cOeOMJI0aNco4YzqoUbIbemozuDM7O9s4I9kN77Q5DjbDUm0G2oZCIeOMZPd7xfbcM2Xze0g6/7vV1IgRI4y27+np6dd23AMCADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcSdhhpenq6kpL634+tra0DuJpoNsP8bAY1FhUVGWe+973vGWdKSkqMM5LdcMyOjg7jTF1dnXHGdiBkf4co/i+bYak254Pf7zfO2AzBlaSMjAzjTE5OjnGmsLDQOHP06FHjzOnTp40zkt0wUptBrjZsh5GmpaUZZ0yH2vb39sc9IACAExQQAMAJ4wLasWOH7r77bgWDQfl8Pm3atCnq+iVLlsjn80VdFixYEKv1AgCGCOMCam9vV0lJidauXdvnNgsWLFBDQ0Pv5e23376qRQIAhh7jR9PLy8tVXl5+2W38fr/VOx0CAK4dA/IY0Pbt25Wbm6tJkyZp2bJlam5u7nPbzs5OhcPhqAsAYOiLeQEtWLBAb775prZu3apf//rXqqqqUnl5eZ9Pb62srFQgEOi92DwtEwAw+MT8dUAPPPBA779vueUWTZs2TRMnTtT27ds1d+7ci7ZftWqVVq5c2ftxOBymhADgGjDgT8OeMGGCcnJyVFNTc8nr/X6/MjMzoy4AgKFvwAvoyJEjam5uVkFBwUDvCgAwiBj/Ca6trS3q3kxtba3279+v7OxsZWdn68UXX9SiRYuUn5+vw4cP6+mnn9b111+v+fPnx3ThAIDBzbiA9uzZo7vuuqv34wuP3yxevFivv/66Dhw4oD/+8Y9qaWlRMBjUvHnz9Itf/MJqjhUAYOgyLqA5c+bI87w+r//zn/98VQu6IBgMKjk5ud/bHz9+PCb77Y+srCzjzPXXX2+csRkSOnv2bOOMzWBMSTp16pRxxuZp9p2dncYZm0Gpkt2gxvT0dOOM6XBHSRo5cqRxxpbJbe+CG264wThjc+7ZDAM+e/ascUY6/xcfU11dXcaZy/1O7YvtMFKbn63JYGiT7ZkFBwBwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACdi/pbcsVJUVKSUlJR+b28zKXjUqFHGGUnKzc01ztx2223GmenTpxtnbN7OvKmpyTgjSc3NzcYZ26nEpkzOnf+VmppqnLGZLtzR0WGcsZkKbjPNWTKffizJ6t2Mbb4nm+nj586dM85Idj9bm8nWkUjEOGPzM5Ls1jdQuAcEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE4k7DDSvLw8o8GQWVlZxvuwHUZaXFxsnJk6dapxxmawqM1xaG9vN87Y7qugoMA4YzN80pbNUFub4Y4235PN2np6eowzkt3QWJt9nTx50jhz7Ngx48zp06eNM5LdsNR4sRlgKknd3d3GGdOhtv09F7gHBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOJOww0hEjRsjv9/d7e5tBiDbDHSUpJSXFKmfKZlBjOBw2zhw5csQ4I9kNMQ0Gg8YZmwGmLS0txhlJRufcBTbng80g1+Tk5LhkJLuBlbW1tcaZzz//3Dizd+9e48ypU6eMM5LU1dVlnLH5XWQ7WNSGzYBV09tTf78f7gEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMJO4y0s7NTnuf1e3ubIZw2GclusGFmZqZxxmYgpMkxu+D06dPGGUnKyckxzowbN844k5Rk/v+kY8eOGWcku+GdNsNI8/PzjTNpaWnGGZvhqpL0zTffGGf+8Y9/GGcOHTpknLG53doO+4zXYFGb263P5zPOSHbfU2trq9H2DCMFACQ0CggA4IRRAVVWVmrGjBnKyMhQbm6uFi5cqOrq6qhtOjo6VFFRodGjR2vkyJFatGiRmpqaYrpoAMDgZ1RAVVVVqqio0K5du/TJJ5+ou7tb8+bNi3pjsieffFIffvih3n//fVVVVenYsWO67777Yr5wAMDgZvQkhC1btkR9vH79euXm5mrv3r2aPXu2QqGQfv/732vDhg36/ve/L0lat26dbrrpJu3atUvf/e53Y7dyAMCgdlWPAYVCIUlSdna2pPNvldvd3a2ysrLebSZPnqyioiLt3Lnzkl+js7NT4XA46gIAGPqsCygSiWjFihW6/fbbNXXqVElSY2OjUlNTL3q/+7y8PDU2Nl7y61RWVioQCPReCgsLbZcEABhErAuooqJCBw8e1DvvvHNVC1i1apVCoVDvpb6+/qq+HgBgcLB6Iery5cv10UcfaceOHRo7dmzv5/Pz89XV1aWWlpaoe0FNTU19vvDO7/dbv1gOADB4Gd0D8jxPy5cv18aNG7Vt2zYVFxdHXT99+nSlpKRo69atvZ+rrq5WXV2dZs2aFZsVAwCGBKN7QBUVFdqwYYM2b96sjIyM3sd1AoGA0tLSFAgE9Oijj2rlypXKzs5WZmamnnjiCc2aNYtnwAEAohgV0Ouvvy5JmjNnTtTn161bpyVLlkiSfvOb3ygpKUmLFi1SZ2en5s+fr9/97ncxWSwAYOjweTZT8AZQOBxWIBBQWVmZ0ZDHhoYG432dO3fOOCMp6nGv/rrpppuMMzYDK20GDdoMPZWkSZMmGWdmzJhhnLnwNH8TJ0+eNM5I5yd5mPr2sz77Y9gw84dfL7zswcSJEyeMM5Ki/ozeX/v27TPO2ExJsRmea3s+mA7hlOI3RNiWzRDT9PR0o+09z1N7e7tCodBlBzEzCw4A4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOWL0jajy0tbUZTQxuaWkx3oftNGwbNu/6avM92UzDHj16tHFGkurq6owzeXl5xhmbScaBQMA4Y7svm0nGF95Ly4TNZOuvv/7aOCNJX375pXHG5nywmT7e1tZmnOnq6jLO4L9Mf6/09zbBPSAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcCJhh5GePHlSycnJ/d4+nsNIbYYh2qwvNTXVOJOUZP5/ikgkYpyRpJEjRxpnPv74Y+PMTTfdZJzJzs42zkhSMBg0zjQ0NBhnbM6Hw4cPG2ds1ibZDWXt7Ow0znR3dxtnbAbu2t7WbW4bNsNpE53P5xuQr8s9IACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwImGHkXZ1dRkN1rQZNtjV1WWcsc2dPXvWOGMzWDSeTIbFXnD06FHjTE1NjXEmJyfHOCNJgUDAOGMzqNFm2GdHR4dxJhwOG2ek+A0WtWEz7NNmgKntvtB/if0bDgAwZFFAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADAiYQdRtre3m40jNNmQGi8hidKDDW8oL293ThjM5T1+PHjxhnJbsCqzTBSm/PBZj/xHMIZiUSs9hUPtre/RP6e4sn0Ntjf4809IACAExQQAMAJowKqrKzUjBkzlJGRodzcXC1cuFDV1dVR28yZM0c+ny/q8vjjj8d00QCAwc+ogKqqqlRRUaFdu3bpk08+UXd3t+bNm3fR3/WXLl2qhoaG3suaNWtiumgAwOBn9CSELVu2RH28fv165ebmau/evZo9e3bv50eMGKH8/PzYrBAAMCRd1WNAoVBIkpSdnR31+bfeeks5OTmaOnWqVq1apTNnzvT5NTo7OxUOh6MuAIChz/pp2JFIRCtWrNDtt9+uqVOn9n7+oYce0rhx4xQMBnXgwAE988wzqq6u1gcffHDJr1NZWakXX3zRdhkAgEHK51k+QX7ZsmX605/+pC+++EJjx47tc7tt27Zp7ty5qqmp0cSJEy+6vrOzU52dnb0fh8NhFRYWavTo0UbPPb9wb8wErwOKP5vXsti8Dsjm9Ty2OV4HdF4iv2Ymnq8DSvTbus15lJ6ebrS953lqb29XKBRSZmZmn9tZ3QNavny5PvroI+3YseOy5SNJpaWlktRnAfn9fvn9fptlAAAGMaMC8jxPTzzxhDZu3Kjt27eruLj4ipn9+/dLkgoKCqwWCAAYmowKqKKiQhs2bNDmzZuVkZGhxsZGSVIgEFBaWpoOHz6sDRs26Ac/+IFGjx6tAwcO6Mknn9Ts2bM1bdq0AfkGAACDk9FjQH397XDdunVasmSJ6uvr9aMf/UgHDx5Ue3u7CgsLde+99+rZZ5+97N8B/1c4HFYgEOAxoCGKx4DO4zGg+OIxoP8atI8BXenAFhYWqqqqyuRLAgCuUQk7DRtDU6L/z9pmXzb30GzE654Wro7NzymebO7lp6amGm1/4R7QlTCMFADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcSNhhpKNGjTIammczdr4/w/IuJV4DNeO1n3gN05TiN6jR9u0YbI7FsGHmN6N47SeehuLgU5u3bLF9CwxTtrfbtLQ040xeXp7R9j09PTp9+vQVt+MeEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcCLhhktdmCdlOtPMZg6V7eyqeO0rkTOJbij+bG3m/OHqJPLtyXY/NueR6Xy7C9tfaY0JV0Ctra2SpK+//trxSq4dQ/EXW7wGQgKDjc0Q5ubmZqt9tba2KhAI9Hm9z0uw//5GIhEdO3ZMGRkZF01ODofDKiwsVH19vTIzMx2t0D2Ow3kch/M4DudxHM5LhOPgeZ5aW1sVDAYvO7U74e4BJSUlaezYsZfdJjMz85o+wS7gOJzHcTiP43Aex+E818fhcvd8LuBJCAAAJyggAIATg6qA/H6/Vq9eLb/f73opTnEczuM4nMdxOI/jcN5gOg4J9yQEAMC1YVDdAwIADB0UEADACQoIAOAEBQQAcGLQFNDatWs1fvx4DR8+XKWlpfrb3/7meklx98ILL8jn80VdJk+e7HpZA27Hjh26++67FQwG5fP5tGnTpqjrPc/T888/r4KCAqWlpamsrEyHDh1ys9gBdKXjsGTJkovOjwULFrhZ7ACprKzUjBkzlJGRodzcXC1cuFDV1dVR23R0dKiiokKjR4/WyJEjtWjRIjU1NTla8cDoz3GYM2fORefD448/7mjFlzYoCujdd9/VypUrtXr1an355ZcqKSnR/Pnzdfz4cddLi7spU6aooaGh9/LFF1+4XtKAa29vV0lJidauXXvJ69esWaPf/va3euONN7R7926lp6dr/vz56ujoiPNKB9aVjoMkLViwIOr8ePvtt+O4woFXVVWliooK7dq1S5988om6u7s1b968qPlmTz75pD788EO9//77qqqq0rFjx3Tfffc5XHXs9ec4SNLSpUujzoc1a9Y4WnEfvEFg5syZXkVFRe/HPT09XjAY9CorKx2uKv5Wr17tlZSUuF6GU5K8jRs39n4ciUS8/Px87+WXX+79XEtLi+f3+723337bwQrj49vHwfM8b/Hixd4999zjZD2uHD9+3JPkVVVVeZ53/mefkpLivf/++73b/POf//QkeTt37nS1zAH37ePgeZ73f//3f95PfvITd4vqh4S/B9TV1aW9e/eqrKys93NJSUkqKyvTzp07Ha7MjUOHDikYDGrChAl6+OGHVVdX53pJTtXW1qqxsTHq/AgEAiotLb0mz4/t27crNzdXkyZN0rJly6ynGA8WoVBIkpSdnS1J2rt3r7q7u6POh8mTJ6uoqGhInw/fPg4XvPXWW8rJydHUqVO1atUqnTlzxsXy+pRww0i/7eTJk+rp6VFeXl7U5/Py8vSvf/3L0arcKC0t1fr16zVp0iQ1NDToxRdf1J133qmDBw8qIyPD9fKcaGxslKRLnh8XrrtWLFiwQPfdd5+Ki4t1+PBh/fznP1d5ebl27typ5ORk18uLuUgkohUrVuj222/X1KlTJZ0/H1JTU5WVlRW17VA+Hy51HCTpoYce0rhx4xQMBnXgwAE988wzqq6u1gcffOBwtdESvoDwX+Xl5b3/njZtmkpLSzVu3Di99957evTRRx2uDInggQce6P33LbfcomnTpmnixInavn275s6d63BlA6OiokIHDx68Jh4HvZy+jsNjjz3W++9bbrlFBQUFmjt3rg4fPqyJEyfGe5mXlPB/gsvJyVFycvJFz2JpampSfn6+o1UlhqysLN14442qqalxvRRnLpwDnB8XmzBhgnJycobk+bF8+XJ99NFH+uyzz6LeviU/P19dXV1qaWmJ2n6ong99HYdLKS0tlaSEOh8SvoBSU1M1ffp0bd26tfdzkUhEW7du1axZsxyuzL22tjYdPnxYBQUFrpfiTHFxsfLz86POj3A4rN27d1/z58eRI0fU3Nw8pM4Pz/O0fPlybdy4Udu2bVNxcXHU9dOnT1dKSkrU+VBdXa26urohdT5c6Thcyv79+yUpsc4H18+C6I933nnH8/v93vr1672vvvrKe+yxx7ysrCyvsbHR9dLi6qc//am3fft2r7a21vvLX/7ilZWVeTk5Od7x48ddL21Atba2evv27fP27dvnSfJeeeUVb9++fd4333zjeZ7n/epXv/KysrK8zZs3ewcOHPDuuecer7i42Dt79qzjlcfW5Y5Da2ur99RTT3k7d+70amtrvU8//dS77bbbvBtuuMHr6OhwvfSYWbZsmRcIBLzt27d7DQ0NvZczZ870bvP44497RUVF3rZt27w9e/Z4s2bN8mbNmuVw1bF3peNQU1PjvfTSS96ePXu82tpab/Pmzd6ECRO82bNnO155tEFRQJ7nea+99ppXVFTkpaamejNnzvR27drleklxd//993sFBQVeamqqd91113n333+/V1NT43pZA+6zzz7zJF10Wbx4sed555+K/dxzz3l5eXme3+/35s6d61VXV7td9AC43HE4c+aMN2/ePG/MmDFeSkqKN27cOG/p0qVD7j9pl/r+JXnr1q3r3ebs2bPej3/8Y2/UqFHeiBEjvHvvvddraGhwt+gBcKXjUFdX582ePdvLzs72/H6/d/3113s/+9nPvFAo5Hbh38LbMQAAnEj4x4AAAEMTBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJz4f4NaCRZkdKxgAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = generate_image(client_list[1].generator, 5, latent_dim)"
      ],
      "metadata": {
        "id": "KT62JAmSIwwF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img[0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "YGK-pLCHJJ2L",
        "outputId": "6a9eb270-579c-4982-ae19-4e75648876e6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO list:\n",
        "- add wandb to the training steps to record metrics\n",
        "- tune the parameters to achieve better performances\n",
        "\n",
        "numbers to consider:\n",
        "\n",
        "number of rounds of training\n",
        "\n",
        "compare:\n",
        "using logits or feature map output ie layer[-2]\n",
        "\n",
        "\n",
        "- set up homogeneous experiments\n",
        "- set up heterogenous experiments"
      ],
      "metadata": {
        "id": "FpDQ82VJOzOH"
      }
    }
  ]
}