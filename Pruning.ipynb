{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOd3qYbSe89lW3NtTdZPyO+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisW2420/FedDistill/blob/main/Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prototype"
      ],
      "metadata": {
        "id": "j0dInRzQ6HOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "SIyHFXls6LCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "WIyDUmTG6d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35961c48-59ae-433d-82e1-e43d6a7d5a46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/242.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "import tf_keras as keras\n",
        "import tempfile\n",
        "from keras.callbacks import EarlyStopping, Callback"
      ],
      "metadata": {
        "id": "ZVBD4_yF6Kaa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: add wandb to all experiments"
      ],
      "metadata": {
        "id": "X3K-OZqGxGxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "from wandb.keras import WandbMetricsLogger"
      ],
      "metadata": {
        "id": "iozTZlIe6h5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset"
      ],
      "metadata": {
        "id": "6v6pgRmS6Px3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
        "validation_split = 0.1"
      ],
      "metadata": {
        "id": "Rk66OzPv6GR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf1a0b4-8145-4cc7-a9f4-c2c5fa3ec231"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "7ih2fKVsE7Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smallCNN():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(28, 28, 1)),\n",
        "          keras.layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(10),\n",
        "      ],\n",
        "      name=\"smallcnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def mediumCNN():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(28, 28, 1)),\n",
        "          keras.layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(10),\n",
        "      ],\n",
        "      name=\"mediumcnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def bigCNN():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(28, 28, 1)),\n",
        "          keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(10),\n",
        "      ],\n",
        "      name=\"bigcnn\",\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "EpzZr20vE6-O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gzk8Qaec5Qyt"
      },
      "outputs": [],
      "source": [
        "# early stopping when training converges on validation loss\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.001,  # only consider as improvement significant changes\n",
        "    patience=2,      # number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='min'        # 'min' because we want to minimize the loss\n",
        ")\n",
        "\n",
        "def trainCNN(model, _epoch, x_train = x_train, y_train = y_train):\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model.fit(x_train, y_train, batch_size=batch_size, epochs=_epoch,validation_split=validation_split, callbacks=[early_stopping])\n",
        "  model.evaluate(x_test, y_test)\n",
        "\n",
        "  return model\n",
        "\n",
        "  # _, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "\n",
        "  # model.save_weights(pretrained_weights)\n",
        "\n",
        "  # return pretrained_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pruning"
      ],
      "metadata": {
        "id": "TjnfgMrEY3Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic implementation"
      ],
      "metadata": {
        "id": "83t9MJb2ZOTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functions\n",
        "def prune_finetrain(base_model, _epochs, target_sparsity = 0.5, x_train = x_train, y_train = y_train):\n",
        "  callbacks = [\n",
        "      sparsity.UpdatePruningStep(),\n",
        "      early_stopping\n",
        "  ]\n",
        "  steps_per_epoch = len(x_train)*(1-validation_split) // batch_size\n",
        "  pruning_schedule = sparsity.PolynomialDecay(initial_sparsity=0, final_sparsity=target_sparsity,\n",
        "                                              begin_step=0, end_step=int(steps_per_epoch*_epochs)) # increase sparsity\n",
        "\n",
        "  model_for_pruning = sparsity.prune_low_magnitude(base_model) #default constant sparsity of 50%\n",
        "  model_for_pruning.summary()\n",
        "\n",
        "  model_for_pruning.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model_for_pruning.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=batch_size,\n",
        "      validation_split=validation_split,\n",
        "      callbacks=callbacks,\n",
        "      epochs=_epochs,\n",
        "  )\n",
        "\n",
        "  return model_for_pruning\n",
        "\n",
        "def get_model_sparsity(model):\n",
        "    total_weights = 0\n",
        "    zero_weights = 0\n",
        "    for weight in model.get_weights():\n",
        "        total_weights += weight.size\n",
        "        zero_weights += np.count_nonzero(weight == 0)\n",
        "    return zero_weights / total_weights\n",
        "\n",
        "def get_gzipped_model_size(model):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, keras_file = tempfile.mkstemp('.h5')\n",
        "  model.save(keras_file, include_optimizer=False)\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(keras_file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "DnzKU0g0hsbj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training base model\n",
        "\n",
        "model = mediumCNN()\n",
        "model = trainCNN(model, 2)\n",
        "_, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "model.save_weights(pretrained_weights)\n",
        "\n",
        "# pruning\n",
        "base_model = mediumCNN()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "pruned_model = prune_finetrain(base_model, 5)\n",
        "\n",
        "# continue training base model for performance comparison\n",
        "base_model_copy = mediumCNN()\n",
        "base_model_copy.load_weights(pretrained_weights)\n",
        "base_model_copy = trainCNN(base_model_copy, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdg3hXYGkxo4",
        "outputId": "15f4643b-6b90-4059-e750-6efd758e0c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "844/844 [==============================] - 29s 6ms/step - loss: 0.3845 - sparse_categorical_accuracy: 0.8798 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9643\n",
            "Epoch 2/2\n",
            "844/844 [==============================] - 3s 4ms/step - loss: 0.1150 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.0775 - val_sparse_categorical_accuracy: 0.9777\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9754\n",
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _3 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_2 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _4 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 3 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_3 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _5 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_1 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 14s 8ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.0781 - val_sparse_categorical_accuracy: 0.9772\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 6s 8ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.0747 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.0675 - val_sparse_categorical_accuracy: 0.9802\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 6s 7ms/step - loss: 0.0722 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9817\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.0650 - val_sparse_categorical_accuracy: 0.9807\n",
            "Epoch 1/5\n",
            "844/844 [==============================] - 6s 5ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.0694 - val_sparse_categorical_accuracy: 0.9800\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 3s 4ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0695 - val_sparse_categorical_accuracy: 0.9782\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 3s 4ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.0590 - val_sparse_categorical_accuracy: 0.9843\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 4s 4ms/step - loss: 0.0641 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0511 - val_sparse_categorical_accuracy: 0.9855\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_stripped = sparsity.strip_pruning(pruned_model)\n",
        "print(\"final model\")\n",
        "pruned_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4uzSF34rnI7",
        "outputId": "578d8480-0d22-4ab4-bdef-7993827db9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final model\n",
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _3 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_2 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _4 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 3 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_3 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _5 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_1 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare accuracy, sparsity and file size\n",
        "print(f\"Base Model test accuracy: {base_model_copy.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "print(f\"Pruned Model test accuracy: {pruned_model.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(base_model_copy) * 100\n",
        "print(f\"Base Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(pruned_model) * 100\n",
        "print(f\"Pruned Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "print('\\n')\n",
        "print(\"Size of gzipped base model: %.2f bytes\" % (get_gzipped_model_size(base_model_copy)))\n",
        "print(\"Size of gzipped pruned model: %.2f bytes\" % (get_gzipped_model_size(pruned_model_stripped)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDY-wn3mp2xd",
        "outputId": "6af58c38-35c7-4473-b1aa-39008f90173a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9836\n",
            "Base Model test accuracy: 0.98%\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9813\n",
            "Pruned Model test accuracy: 0.98%\n",
            "Base Model sparsity: 0.00%\n",
            "Pruned Model sparsity: 49.74%\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped base model: 25706.00 bytes\n",
            "Size of gzipped pruned model: 16939.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning to as small as possible with > 99.5% accuracy as best"
      ],
      "metadata": {
        "id": "4X1KGhoAv9QD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: make this feature work:\n",
        "\n",
        "either: target sparsity or target accuracy with max sparsity\n",
        "\n",
        "early ending on convergence"
      ],
      "metadata": {
        "id": "N24wDCFKfw8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomPolynomialDecay(sparsity.PolynomialDecay):\n",
        "    def __init__(self, initial_sparsity, final_sparsity, begin_step, end_step, power=3, frequency=100):\n",
        "        super().__init__(initial_sparsity, final_sparsity, begin_step, end_step, power=power, frequency=frequency)\n",
        "        self.freeze_sparsity = False\n",
        "        self.current_sparsity = 0\n",
        "\n",
        "    # def _should_prune_in_step(self, step, begin_step, end_step, frequency):\n",
        "    #     print('testing')\n",
        "    #     if self.freeze_sparsity:\n",
        "    #         print('freezed')\n",
        "    #         return False\n",
        "    #     else:\n",
        "    #         return sparsity.PruningSchedule._should_prune_in_step(self, step, begin_step, end_step, frequency)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        print('testing')\n",
        "        if self.freeze_sparsity:\n",
        "          return (False, self.current_sparsity)\n",
        "        else:\n",
        "          _, self.current_sparsity = super().__call__(step)\n",
        "          return (_, self.current_sparsity)\n",
        "\n",
        "    def freeze(self):\n",
        "        self.freeze_sparsity = True\n",
        "\n",
        "class FreezePruningOnAccuracyDrop(Callback):\n",
        "    def __init__(self, pruning_schedule, threshold=0.96):\n",
        "        super().__init__()\n",
        "        self.pruning_schedule = pruning_schedule\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        current_accuracy = logs.get('sparse_categorical_accuracy')\n",
        "        if current_accuracy < self.threshold:\n",
        "            print(f\"\\nAccuracy has dropped below {self.threshold*100:.2f}%, freezing further pruning.\")\n",
        "            self.pruning_schedule.freeze()\n",
        "            print(self.pruning_schedule.freeze_sparsity)"
      ],
      "metadata": {
        "id": "EHYYl3cKlAkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function\n",
        "# save good performance ones\n",
        "# class CustomEarlyStopping(Callback):\n",
        "#     def on_batch_end(self, batch, logs=None):\n",
        "#         current_accuracy = logs.get('sparse_categorical_accuracy')\n",
        "#         if current_accuracy <= 0.975:\n",
        "#             print(f\"\\nStopping training as accuracy has dropped to {current_accuracy*100:.2f}%\")\n",
        "#             self.model.stop_training = True\n",
        "\n",
        "def prune_finetrain(base_model, _epochs):\n",
        "  steps_per_epoch = len(x_train)*(1-validation_split) // batch_size\n",
        "  print('steps_per_epoch: ', steps_per_epoch)\n",
        "  # pruning_schedule = sparsity.PolynomialDecay(initial_sparsity=0.20, final_sparsity=0.70,\n",
        "  #                                             begin_step=0, end_step=int(steps_per_epoch*_epochs)) # increase sparsity\n",
        "\n",
        "  total_steps = int(_epochs * steps_per_epoch)\n",
        "  pruning_schedule = CustomPolynomialDecay(\n",
        "    initial_sparsity=0.0,\n",
        "    final_sparsity=0.9,\n",
        "    begin_step=batch_size,\n",
        "    end_step=total_steps,\n",
        "    power=3\n",
        "  )\n",
        "\n",
        "  model_for_pruning = sparsity.prune_low_magnitude(base_model, pruning_schedule=pruning_schedule)\n",
        "  model_for_pruning.summary()\n",
        "\n",
        "\n",
        "  callbacks = [\n",
        "    sparsity.UpdatePruningStep(),\n",
        "    sparsity.PruningSummaries(log_dir='/path/to/logs'),\n",
        "    FreezePruningOnAccuracyDrop(pruning_schedule)\n",
        "  ]\n",
        "\n",
        "\n",
        "  model_for_pruning.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model_for_pruning.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=batch_size,\n",
        "      validation_split=validation_split,\n",
        "      callbacks=callbacks,\n",
        "      epochs=_epochs,\n",
        "  )\n",
        "\n",
        "  return model_for_pruning"
      ],
      "metadata": {
        "id": "QBV-LExY3ll8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adaptive pruning\n",
        "base_model = mediumCNN()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "adaptive_pruned_model = prune_finetrain(base_model, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpekp7an6Afn",
        "outputId": "06625f1f-7f81-469f-b5a0-91c8c9d8ccb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps_per_epoch:  843.0\n",
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _48 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 32 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_32 (PruneLowMagnit                                      \n",
            " ude)                                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _49 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 33 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_33 (PruneLowMagnit                                      \n",
            " ude)                                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _50 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_16 (PruneLowMagnitude)                                        \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 16 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "testing\n",
            "  1/844 [..............................] - ETA: 1:11:33 - loss: 0.0977 - sparse_categorical_accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0107s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "844/844 [==============================] - 12s 8ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.0855 - val_sparse_categorical_accuracy: 0.9732\n",
            "Epoch 2/3\n",
            "  1/844 [..............................] - ETA: 9s - loss: 0.0804 - sparse_categorical_accuracy: 0.9688\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "221/844 [======>.......................] - ETA: 4s - loss: 0.1262 - sparse_categorical_accuracy: 0.9618\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "228/844 [=======>......................] - ETA: 4s - loss: 0.1400 - sparse_categorical_accuracy: 0.9576\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "235/844 [=======>......................] - ETA: 4s - loss: 0.1461 - sparse_categorical_accuracy: 0.9551\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "242/844 [=======>......................] - ETA: 4s - loss: 0.1485 - sparse_categorical_accuracy: 0.9540\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "249/844 [=======>......................] - ETA: 4s - loss: 0.1487 - sparse_categorical_accuracy: 0.9539\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "256/844 [========>.....................] - ETA: 3s - loss: 0.1486 - sparse_categorical_accuracy: 0.9539\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "263/844 [========>.....................] - ETA: 3s - loss: 0.1494 - sparse_categorical_accuracy: 0.9536\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "270/844 [========>.....................] - ETA: 3s - loss: 0.1504 - sparse_categorical_accuracy: 0.9536\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "276/844 [========>.....................] - ETA: 3s - loss: 0.1501 - sparse_categorical_accuracy: 0.9537\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "282/844 [=========>....................] - ETA: 3s - loss: 0.1502 - sparse_categorical_accuracy: 0.9538\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "288/844 [=========>....................] - ETA: 3s - loss: 0.1495 - sparse_categorical_accuracy: 0.9541\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "294/844 [=========>....................] - ETA: 3s - loss: 0.1490 - sparse_categorical_accuracy: 0.9543\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "300/844 [=========>....................] - ETA: 3s - loss: 0.1487 - sparse_categorical_accuracy: 0.9544\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "306/844 [=========>....................] - ETA: 3s - loss: 0.1486 - sparse_categorical_accuracy: 0.9545\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "312/844 [==========>...................] - ETA: 3s - loss: 0.1482 - sparse_categorical_accuracy: 0.9542\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "319/844 [==========>...................] - ETA: 3s - loss: 0.1484 - sparse_categorical_accuracy: 0.9539\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "325/844 [==========>...................] - ETA: 3s - loss: 0.1617 - sparse_categorical_accuracy: 0.9498\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "331/844 [==========>...................] - ETA: 3s - loss: 0.1658 - sparse_categorical_accuracy: 0.9485\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "337/844 [==========>...................] - ETA: 3s - loss: 0.1663 - sparse_categorical_accuracy: 0.9485\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "344/844 [===========>..................] - ETA: 3s - loss: 0.1683 - sparse_categorical_accuracy: 0.9480\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "351/844 [===========>..................] - ETA: 3s - loss: 0.1691 - sparse_categorical_accuracy: 0.9480\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "357/844 [===========>..................] - ETA: 3s - loss: 0.1690 - sparse_categorical_accuracy: 0.9483\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "363/844 [===========>..................] - ETA: 3s - loss: 0.1688 - sparse_categorical_accuracy: 0.9486\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "370/844 [============>.................] - ETA: 3s - loss: 0.1684 - sparse_categorical_accuracy: 0.9489\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "376/844 [============>.................] - ETA: 3s - loss: 0.1686 - sparse_categorical_accuracy: 0.9491\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "382/844 [============>.................] - ETA: 3s - loss: 0.1681 - sparse_categorical_accuracy: 0.9492\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "389/844 [============>.................] - ETA: 3s - loss: 0.1684 - sparse_categorical_accuracy: 0.9492\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "395/844 [=============>................] - ETA: 3s - loss: 0.1688 - sparse_categorical_accuracy: 0.9493\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "401/844 [=============>................] - ETA: 3s - loss: 0.1687 - sparse_categorical_accuracy: 0.9496\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "407/844 [=============>................] - ETA: 3s - loss: 0.1688 - sparse_categorical_accuracy: 0.9496\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "414/844 [=============>................] - ETA: 3s - loss: 0.1675 - sparse_categorical_accuracy: 0.9502\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "420/844 [=============>................] - ETA: 3s - loss: 0.1674 - sparse_categorical_accuracy: 0.9503\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "426/844 [==============>...............] - ETA: 3s - loss: 0.1706 - sparse_categorical_accuracy: 0.9489\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "432/844 [==============>...............] - ETA: 3s - loss: 0.1725 - sparse_categorical_accuracy: 0.9486\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "438/844 [==============>...............] - ETA: 3s - loss: 0.1733 - sparse_categorical_accuracy: 0.9484\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "443/844 [==============>...............] - ETA: 3s - loss: 0.1735 - sparse_categorical_accuracy: 0.9485\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "447/844 [==============>...............] - ETA: 3s - loss: 0.1736 - sparse_categorical_accuracy: 0.9487\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "450/844 [==============>...............] - ETA: 3s - loss: 0.1738 - sparse_categorical_accuracy: 0.9487\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "454/844 [===============>..............] - ETA: 3s - loss: 0.1744 - sparse_categorical_accuracy: 0.9485\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "459/844 [===============>..............] - ETA: 3s - loss: 0.1742 - sparse_categorical_accuracy: 0.9487\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "463/844 [===============>..............] - ETA: 3s - loss: 0.1743 - sparse_categorical_accuracy: 0.9487\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "467/844 [===============>..............] - ETA: 2s - loss: 0.1740 - sparse_categorical_accuracy: 0.9488\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "471/844 [===============>..............] - ETA: 2s - loss: 0.1740 - sparse_categorical_accuracy: 0.9489\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "476/844 [===============>..............] - ETA: 2s - loss: 0.1741 - sparse_categorical_accuracy: 0.9489\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "480/844 [================>.............] - ETA: 2s - loss: 0.1742 - sparse_categorical_accuracy: 0.9488\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "484/844 [================>.............] - ETA: 2s - loss: 0.1741 - sparse_categorical_accuracy: 0.9489\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "488/844 [================>.............] - ETA: 2s - loss: 0.1741 - sparse_categorical_accuracy: 0.9488\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "492/844 [================>.............] - ETA: 2s - loss: 0.1736 - sparse_categorical_accuracy: 0.9491\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "496/844 [================>.............] - ETA: 2s - loss: 0.1736 - sparse_categorical_accuracy: 0.9490\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "500/844 [================>.............] - ETA: 2s - loss: 0.1739 - sparse_categorical_accuracy: 0.9489\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "504/844 [================>.............] - ETA: 2s - loss: 0.1736 - sparse_categorical_accuracy: 0.9490\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "509/844 [=================>............] - ETA: 2s - loss: 0.1732 - sparse_categorical_accuracy: 0.9491\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "514/844 [=================>............] - ETA: 2s - loss: 0.1732 - sparse_categorical_accuracy: 0.9492\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "518/844 [=================>............] - ETA: 2s - loss: 0.1731 - sparse_categorical_accuracy: 0.9492\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "522/844 [=================>............] - ETA: 2s - loss: 0.1773 - sparse_categorical_accuracy: 0.9478\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "526/844 [=================>............] - ETA: 2s - loss: 0.1809 - sparse_categorical_accuracy: 0.9464\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "530/844 [=================>............] - ETA: 2s - loss: 0.1822 - sparse_categorical_accuracy: 0.9460\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "534/844 [=================>............] - ETA: 2s - loss: 0.1832 - sparse_categorical_accuracy: 0.9456\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "539/844 [==================>...........] - ETA: 2s - loss: 0.1843 - sparse_categorical_accuracy: 0.9452\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "544/844 [==================>...........] - ETA: 2s - loss: 0.1856 - sparse_categorical_accuracy: 0.9449\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "549/844 [==================>...........] - ETA: 2s - loss: 0.1858 - sparse_categorical_accuracy: 0.9450\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "554/844 [==================>...........] - ETA: 2s - loss: 0.1863 - sparse_categorical_accuracy: 0.9449\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "559/844 [==================>...........] - ETA: 2s - loss: 0.1865 - sparse_categorical_accuracy: 0.9448\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "563/844 [===================>..........] - ETA: 2s - loss: 0.1868 - sparse_categorical_accuracy: 0.9447\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "568/844 [===================>..........] - ETA: 2s - loss: 0.1873 - sparse_categorical_accuracy: 0.9445\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "572/844 [===================>..........] - ETA: 2s - loss: 0.1879 - sparse_categorical_accuracy: 0.9444\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "576/844 [===================>..........] - ETA: 2s - loss: 0.1886 - sparse_categorical_accuracy: 0.9443\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "580/844 [===================>..........] - ETA: 2s - loss: 0.1885 - sparse_categorical_accuracy: 0.9442\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "584/844 [===================>..........] - ETA: 2s - loss: 0.1885 - sparse_categorical_accuracy: 0.9441\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "588/844 [===================>..........] - ETA: 2s - loss: 0.1885 - sparse_categorical_accuracy: 0.9441\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "592/844 [====================>.........] - ETA: 2s - loss: 0.1886 - sparse_categorical_accuracy: 0.9441\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "595/844 [====================>.........] - ETA: 2s - loss: 0.1884 - sparse_categorical_accuracy: 0.9442\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "599/844 [====================>.........] - ETA: 2s - loss: 0.1887 - sparse_categorical_accuracy: 0.9442\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "603/844 [====================>.........] - ETA: 2s - loss: 0.1885 - sparse_categorical_accuracy: 0.9443\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "607/844 [====================>.........] - ETA: 2s - loss: 0.1886 - sparse_categorical_accuracy: 0.9444\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "611/844 [====================>.........] - ETA: 2s - loss: 0.1885 - sparse_categorical_accuracy: 0.9445\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "615/844 [====================>.........] - ETA: 2s - loss: 0.1889 - sparse_categorical_accuracy: 0.9444\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "620/844 [=====================>........] - ETA: 2s - loss: 0.1904 - sparse_categorical_accuracy: 0.9436\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "624/844 [=====================>........] - ETA: 2s - loss: 0.1934 - sparse_categorical_accuracy: 0.9428\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "628/844 [=====================>........] - ETA: 2s - loss: 0.1955 - sparse_categorical_accuracy: 0.9422\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "632/844 [=====================>........] - ETA: 1s - loss: 0.1963 - sparse_categorical_accuracy: 0.9421\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "636/844 [=====================>........] - ETA: 1s - loss: 0.1969 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "640/844 [=====================>........] - ETA: 1s - loss: 0.1970 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "644/844 [=====================>........] - ETA: 1s - loss: 0.1975 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "648/844 [======================>.......] - ETA: 1s - loss: 0.1977 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "652/844 [======================>.......] - ETA: 1s - loss: 0.1979 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "656/844 [======================>.......] - ETA: 1s - loss: 0.1981 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "660/844 [======================>.......] - ETA: 1s - loss: 0.1984 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "664/844 [======================>.......] - ETA: 1s - loss: 0.1983 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "668/844 [======================>.......] - ETA: 1s - loss: 0.1984 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "673/844 [======================>.......] - ETA: 1s - loss: 0.1986 - sparse_categorical_accuracy: 0.9417\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "677/844 [=======================>......] - ETA: 1s - loss: 0.1986 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "682/844 [=======================>......] - ETA: 1s - loss: 0.1986 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "686/844 [=======================>......] - ETA: 1s - loss: 0.1988 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "690/844 [=======================>......] - ETA: 1s - loss: 0.1991 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "693/844 [=======================>......] - ETA: 1s - loss: 0.1990 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "697/844 [=======================>......] - ETA: 1s - loss: 0.1989 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "700/844 [=======================>......] - ETA: 1s - loss: 0.1988 - sparse_categorical_accuracy: 0.9420\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "704/844 [========================>.....] - ETA: 1s - loss: 0.1988 - sparse_categorical_accuracy: 0.9420\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "708/844 [========================>.....] - ETA: 1s - loss: 0.1989 - sparse_categorical_accuracy: 0.9420\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "714/844 [========================>.....] - ETA: 1s - loss: 0.1986 - sparse_categorical_accuracy: 0.9422\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "719/844 [========================>.....] - ETA: 1s - loss: 0.1984 - sparse_categorical_accuracy: 0.9423\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "725/844 [========================>.....] - ETA: 1s - loss: 0.1990 - sparse_categorical_accuracy: 0.9420\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "731/844 [========================>.....] - ETA: 1s - loss: 0.1991 - sparse_categorical_accuracy: 0.9420\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "738/844 [=========================>....] - ETA: 1s - loss: 0.1990 - sparse_categorical_accuracy: 0.9419\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "744/844 [=========================>....] - ETA: 0s - loss: 0.1991 - sparse_categorical_accuracy: 0.9420\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "750/844 [=========================>....] - ETA: 0s - loss: 0.1993 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "756/844 [=========================>....] - ETA: 0s - loss: 0.1994 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "762/844 [==========================>...] - ETA: 0s - loss: 0.1994 - sparse_categorical_accuracy: 0.9417\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "767/844 [==========================>...] - ETA: 0s - loss: 0.1999 - sparse_categorical_accuracy: 0.9416\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "772/844 [==========================>...] - ETA: 0s - loss: 0.1996 - sparse_categorical_accuracy: 0.9417\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "777/844 [==========================>...] - ETA: 0s - loss: 0.1996 - sparse_categorical_accuracy: 0.9416\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "782/844 [==========================>...] - ETA: 0s - loss: 0.1993 - sparse_categorical_accuracy: 0.9417\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "788/844 [===========================>..] - ETA: 0s - loss: 0.1995 - sparse_categorical_accuracy: 0.9416\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "794/844 [===========================>..] - ETA: 0s - loss: 0.1992 - sparse_categorical_accuracy: 0.9416\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "800/844 [===========================>..] - ETA: 0s - loss: 0.1988 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "806/844 [===========================>..] - ETA: 0s - loss: 0.1989 - sparse_categorical_accuracy: 0.9417\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "812/844 [===========================>..] - ETA: 0s - loss: 0.1988 - sparse_categorical_accuracy: 0.9418\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "817/844 [============================>.] - ETA: 0s - loss: 0.1986 - sparse_categorical_accuracy: 0.9417\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "821/844 [============================>.] - ETA: 0s - loss: 0.1999 - sparse_categorical_accuracy: 0.9413\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "826/844 [============================>.] - ETA: 0s - loss: 0.2014 - sparse_categorical_accuracy: 0.9409\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "831/844 [============================>.] - ETA: 0s - loss: 0.2021 - sparse_categorical_accuracy: 0.9407\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "836/844 [============================>.] - ETA: 0s - loss: 0.2032 - sparse_categorical_accuracy: 0.9405\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "842/844 [============================>.] - ETA: 0s - loss: 0.2038 - sparse_categorical_accuracy: 0.9404\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "844/844 [==============================] - 9s 10ms/step - loss: 0.2039 - sparse_categorical_accuracy: 0.9403 - val_loss: 0.2472 - val_sparse_categorical_accuracy: 0.9323\n",
            "Epoch 3/3\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "  1/844 [..............................] - ETA: 9s - loss: 0.2095 - sparse_categorical_accuracy: 0.9375\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "  8/844 [..............................] - ETA: 6s - loss: 0.2800 - sparse_categorical_accuracy: 0.9160\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 15/844 [..............................] - ETA: 6s - loss: 0.3010 - sparse_categorical_accuracy: 0.9125\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 22/844 [..............................] - ETA: 6s - loss: 0.2881 - sparse_categorical_accuracy: 0.9197\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 28/844 [..............................] - ETA: 6s - loss: 0.2812 - sparse_categorical_accuracy: 0.9191\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 35/844 [>.............................] - ETA: 6s - loss: 0.2671 - sparse_categorical_accuracy: 0.9210\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 41/844 [>.............................] - ETA: 6s - loss: 0.2671 - sparse_categorical_accuracy: 0.9196\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 48/844 [>.............................] - ETA: 6s - loss: 0.2627 - sparse_categorical_accuracy: 0.9212\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 53/844 [>.............................] - ETA: 6s - loss: 0.2586 - sparse_categorical_accuracy: 0.9225\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 59/844 [=>............................] - ETA: 6s - loss: 0.2592 - sparse_categorical_accuracy: 0.9221\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 65/844 [=>............................] - ETA: 6s - loss: 0.2532 - sparse_categorical_accuracy: 0.9240\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 72/844 [=>............................] - ETA: 6s - loss: 0.2519 - sparse_categorical_accuracy: 0.9243\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 78/844 [=>............................] - ETA: 6s - loss: 0.3027 - sparse_categorical_accuracy: 0.9060\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 84/844 [=>............................] - ETA: 6s - loss: 0.3648 - sparse_categorical_accuracy: 0.8852\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 89/844 [==>...........................] - ETA: 6s - loss: 0.3833 - sparse_categorical_accuracy: 0.8794\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            " 95/844 [==>...........................] - ETA: 6s - loss: 0.3974 - sparse_categorical_accuracy: 0.8748\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "100/844 [==>...........................] - ETA: 6s - loss: 0.4044 - sparse_categorical_accuracy: 0.8720\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "106/844 [==>...........................] - ETA: 6s - loss: 0.4108 - sparse_categorical_accuracy: 0.8712\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "111/844 [==>...........................] - ETA: 6s - loss: 0.4113 - sparse_categorical_accuracy: 0.8722\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "117/844 [===>..........................] - ETA: 6s - loss: 0.4125 - sparse_categorical_accuracy: 0.8727\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "123/844 [===>..........................] - ETA: 6s - loss: 0.4129 - sparse_categorical_accuracy: 0.8733\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "129/844 [===>..........................] - ETA: 6s - loss: 0.4119 - sparse_categorical_accuracy: 0.8738\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "135/844 [===>..........................] - ETA: 6s - loss: 0.4086 - sparse_categorical_accuracy: 0.8751\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "141/844 [====>.........................] - ETA: 6s - loss: 0.4082 - sparse_categorical_accuracy: 0.8762\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "147/844 [====>.........................] - ETA: 6s - loss: 0.4046 - sparse_categorical_accuracy: 0.8780\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "153/844 [====>.........................] - ETA: 6s - loss: 0.4009 - sparse_categorical_accuracy: 0.8793\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "159/844 [====>.........................] - ETA: 6s - loss: 0.3989 - sparse_categorical_accuracy: 0.8800\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "164/844 [====>.........................] - ETA: 6s - loss: 0.3979 - sparse_categorical_accuracy: 0.8803\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "169/844 [=====>........................] - ETA: 6s - loss: 0.3948 - sparse_categorical_accuracy: 0.8817\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "175/844 [=====>........................] - ETA: 6s - loss: 0.3922 - sparse_categorical_accuracy: 0.8830\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "181/844 [=====>........................] - ETA: 6s - loss: 0.4012 - sparse_categorical_accuracy: 0.8794\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "187/844 [=====>........................] - ETA: 6s - loss: 0.4028 - sparse_categorical_accuracy: 0.8794\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "193/844 [=====>........................] - ETA: 6s - loss: 0.4040 - sparse_categorical_accuracy: 0.8797\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "198/844 [======>.......................] - ETA: 6s - loss: 0.4034 - sparse_categorical_accuracy: 0.8803\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "204/844 [======>.......................] - ETA: 5s - loss: 0.4035 - sparse_categorical_accuracy: 0.8801\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "209/844 [======>.......................] - ETA: 5s - loss: 0.4035 - sparse_categorical_accuracy: 0.8803\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "215/844 [======>.......................] - ETA: 5s - loss: 0.4045 - sparse_categorical_accuracy: 0.8795\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "220/844 [======>.......................] - ETA: 5s - loss: 0.4037 - sparse_categorical_accuracy: 0.8795\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "226/844 [=======>......................] - ETA: 5s - loss: 0.4026 - sparse_categorical_accuracy: 0.8801\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "232/844 [=======>......................] - ETA: 5s - loss: 0.4020 - sparse_categorical_accuracy: 0.8807\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "238/844 [=======>......................] - ETA: 5s - loss: 0.4001 - sparse_categorical_accuracy: 0.8814\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "244/844 [=======>......................] - ETA: 5s - loss: 0.3993 - sparse_categorical_accuracy: 0.8820\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "249/844 [=======>......................] - ETA: 5s - loss: 0.3989 - sparse_categorical_accuracy: 0.8822\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "254/844 [========>.....................] - ETA: 5s - loss: 0.3987 - sparse_categorical_accuracy: 0.8825\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "259/844 [========>.....................] - ETA: 5s - loss: 0.3984 - sparse_categorical_accuracy: 0.8824\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "264/844 [========>.....................] - ETA: 5s - loss: 0.3974 - sparse_categorical_accuracy: 0.8826\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "270/844 [========>.....................] - ETA: 5s - loss: 0.3965 - sparse_categorical_accuracy: 0.8829\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "276/844 [========>.....................] - ETA: 5s - loss: 0.3950 - sparse_categorical_accuracy: 0.8835\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "282/844 [=========>....................] - ETA: 5s - loss: 0.3951 - sparse_categorical_accuracy: 0.8834\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "287/844 [=========>....................] - ETA: 5s - loss: 0.3945 - sparse_categorical_accuracy: 0.8835\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "293/844 [=========>....................] - ETA: 5s - loss: 0.3937 - sparse_categorical_accuracy: 0.8840\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "299/844 [=========>....................] - ETA: 5s - loss: 0.3920 - sparse_categorical_accuracy: 0.8846\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "304/844 [=========>....................] - ETA: 5s - loss: 0.3911 - sparse_categorical_accuracy: 0.8848\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "310/844 [==========>...................] - ETA: 5s - loss: 0.3893 - sparse_categorical_accuracy: 0.8853\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "315/844 [==========>...................] - ETA: 5s - loss: 0.3882 - sparse_categorical_accuracy: 0.8855\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "320/844 [==========>...................] - ETA: 5s - loss: 0.3878 - sparse_categorical_accuracy: 0.8854\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "326/844 [==========>...................] - ETA: 4s - loss: 0.3860 - sparse_categorical_accuracy: 0.8856\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "331/844 [==========>...................] - ETA: 4s - loss: 0.3839 - sparse_categorical_accuracy: 0.8861\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "337/844 [==========>...................] - ETA: 4s - loss: 0.3828 - sparse_categorical_accuracy: 0.8859\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "342/844 [===========>..................] - ETA: 4s - loss: 0.3813 - sparse_categorical_accuracy: 0.8861\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "347/844 [===========>..................] - ETA: 4s - loss: 0.3792 - sparse_categorical_accuracy: 0.8868\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "352/844 [===========>..................] - ETA: 4s - loss: 0.3784 - sparse_categorical_accuracy: 0.8871\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "357/844 [===========>..................] - ETA: 4s - loss: 0.3764 - sparse_categorical_accuracy: 0.8877\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "362/844 [===========>..................] - ETA: 4s - loss: 0.3751 - sparse_categorical_accuracy: 0.8880\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "366/844 [============>.................] - ETA: 4s - loss: 0.3739 - sparse_categorical_accuracy: 0.8883\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "372/844 [============>.................] - ETA: 4s - loss: 0.3725 - sparse_categorical_accuracy: 0.8888\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "377/844 [============>.................] - ETA: 4s - loss: 0.3709 - sparse_categorical_accuracy: 0.8893\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "383/844 [============>.................] - ETA: 4s - loss: 0.3705 - sparse_categorical_accuracy: 0.8893\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "388/844 [============>.................] - ETA: 4s - loss: 0.3695 - sparse_categorical_accuracy: 0.8895\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "393/844 [============>.................] - ETA: 4s - loss: 0.3686 - sparse_categorical_accuracy: 0.8898\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "399/844 [=============>................] - ETA: 4s - loss: 0.3673 - sparse_categorical_accuracy: 0.8903\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "405/844 [=============>................] - ETA: 4s - loss: 0.3669 - sparse_categorical_accuracy: 0.8905\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "410/844 [=============>................] - ETA: 4s - loss: 0.3672 - sparse_categorical_accuracy: 0.8902\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "416/844 [=============>................] - ETA: 4s - loss: 0.3669 - sparse_categorical_accuracy: 0.8903\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "422/844 [==============>...............] - ETA: 4s - loss: 0.3658 - sparse_categorical_accuracy: 0.8906\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "428/844 [==============>...............] - ETA: 4s - loss: 0.3652 - sparse_categorical_accuracy: 0.8908\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "433/844 [==============>...............] - ETA: 4s - loss: 0.3641 - sparse_categorical_accuracy: 0.8911\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "439/844 [==============>...............] - ETA: 3s - loss: 0.3623 - sparse_categorical_accuracy: 0.8917\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "445/844 [==============>...............] - ETA: 3s - loss: 0.3606 - sparse_categorical_accuracy: 0.8922\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "451/844 [===============>..............] - ETA: 3s - loss: 0.3601 - sparse_categorical_accuracy: 0.8922\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "456/844 [===============>..............] - ETA: 3s - loss: 0.3590 - sparse_categorical_accuracy: 0.8925\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "460/844 [===============>..............] - ETA: 3s - loss: 0.3588 - sparse_categorical_accuracy: 0.8925\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "464/844 [===============>..............] - ETA: 3s - loss: 0.3589 - sparse_categorical_accuracy: 0.8921\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "469/844 [===============>..............] - ETA: 3s - loss: 0.3587 - sparse_categorical_accuracy: 0.8921\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "474/844 [===============>..............] - ETA: 3s - loss: 0.3585 - sparse_categorical_accuracy: 0.8921\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "479/844 [================>.............] - ETA: 3s - loss: 0.3582 - sparse_categorical_accuracy: 0.8922\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "484/844 [================>.............] - ETA: 3s - loss: 0.3574 - sparse_categorical_accuracy: 0.8925\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "490/844 [================>.............] - ETA: 3s - loss: 0.3567 - sparse_categorical_accuracy: 0.8925\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "495/844 [================>.............] - ETA: 3s - loss: 0.3561 - sparse_categorical_accuracy: 0.8926\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "500/844 [================>.............] - ETA: 3s - loss: 0.3557 - sparse_categorical_accuracy: 0.8926\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "505/844 [================>.............] - ETA: 3s - loss: 0.3550 - sparse_categorical_accuracy: 0.8928\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "511/844 [=================>............] - ETA: 3s - loss: 0.3538 - sparse_categorical_accuracy: 0.8931\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "516/844 [=================>............] - ETA: 3s - loss: 0.3532 - sparse_categorical_accuracy: 0.8931\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "522/844 [=================>............] - ETA: 3s - loss: 0.3520 - sparse_categorical_accuracy: 0.8936\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "526/844 [=================>............] - ETA: 3s - loss: 0.3515 - sparse_categorical_accuracy: 0.8938\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "531/844 [=================>............] - ETA: 3s - loss: 0.3511 - sparse_categorical_accuracy: 0.8939\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "536/844 [==================>...........] - ETA: 3s - loss: 0.3506 - sparse_categorical_accuracy: 0.8940\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "541/844 [==================>...........] - ETA: 3s - loss: 0.3501 - sparse_categorical_accuracy: 0.8941\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "546/844 [==================>...........] - ETA: 2s - loss: 0.3491 - sparse_categorical_accuracy: 0.8943\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "551/844 [==================>...........] - ETA: 2s - loss: 0.3486 - sparse_categorical_accuracy: 0.8946\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "556/844 [==================>...........] - ETA: 2s - loss: 0.3485 - sparse_categorical_accuracy: 0.8944\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "560/844 [==================>...........] - ETA: 2s - loss: 0.3486 - sparse_categorical_accuracy: 0.8943\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "566/844 [===================>..........] - ETA: 2s - loss: 0.3484 - sparse_categorical_accuracy: 0.8943\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "571/844 [===================>..........] - ETA: 2s - loss: 0.3481 - sparse_categorical_accuracy: 0.8944\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "575/844 [===================>..........] - ETA: 2s - loss: 0.3474 - sparse_categorical_accuracy: 0.8946\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "579/844 [===================>..........] - ETA: 2s - loss: 0.3468 - sparse_categorical_accuracy: 0.8947\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "584/844 [===================>..........] - ETA: 2s - loss: 0.3462 - sparse_categorical_accuracy: 0.8948\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "590/844 [===================>..........] - ETA: 2s - loss: 0.3452 - sparse_categorical_accuracy: 0.8951\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "596/844 [====================>.........] - ETA: 2s - loss: 0.3449 - sparse_categorical_accuracy: 0.8950\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "602/844 [====================>.........] - ETA: 2s - loss: 0.3434 - sparse_categorical_accuracy: 0.8955\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "606/844 [====================>.........] - ETA: 2s - loss: 0.3430 - sparse_categorical_accuracy: 0.8956\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "611/844 [====================>.........] - ETA: 2s - loss: 0.3427 - sparse_categorical_accuracy: 0.8956\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "615/844 [====================>.........] - ETA: 2s - loss: 0.3420 - sparse_categorical_accuracy: 0.8957\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "620/844 [=====================>........] - ETA: 2s - loss: 0.3410 - sparse_categorical_accuracy: 0.8959\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "625/844 [=====================>........] - ETA: 2s - loss: 0.3401 - sparse_categorical_accuracy: 0.8960\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "630/844 [=====================>........] - ETA: 2s - loss: 0.3403 - sparse_categorical_accuracy: 0.8960\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "636/844 [=====================>........] - ETA: 2s - loss: 0.3393 - sparse_categorical_accuracy: 0.8963\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "641/844 [=====================>........] - ETA: 2s - loss: 0.3386 - sparse_categorical_accuracy: 0.8965\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "645/844 [=====================>........] - ETA: 2s - loss: 0.3382 - sparse_categorical_accuracy: 0.8966\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "649/844 [======================>.......] - ETA: 1s - loss: 0.3375 - sparse_categorical_accuracy: 0.8968\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "653/844 [======================>.......] - ETA: 1s - loss: 0.3372 - sparse_categorical_accuracy: 0.8969\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "658/844 [======================>.......] - ETA: 1s - loss: 0.3368 - sparse_categorical_accuracy: 0.8971\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "663/844 [======================>.......] - ETA: 1s - loss: 0.3358 - sparse_categorical_accuracy: 0.8974\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "668/844 [======================>.......] - ETA: 1s - loss: 0.3351 - sparse_categorical_accuracy: 0.8976\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "673/844 [======================>.......] - ETA: 1s - loss: 0.3343 - sparse_categorical_accuracy: 0.8977\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "679/844 [=======================>......] - ETA: 1s - loss: 0.3339 - sparse_categorical_accuracy: 0.8978\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "683/844 [=======================>......] - ETA: 1s - loss: 0.3336 - sparse_categorical_accuracy: 0.8979\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "688/844 [=======================>......] - ETA: 1s - loss: 0.3332 - sparse_categorical_accuracy: 0.8980\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "693/844 [=======================>......] - ETA: 1s - loss: 0.3329 - sparse_categorical_accuracy: 0.8981\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "699/844 [=======================>......] - ETA: 1s - loss: 0.3325 - sparse_categorical_accuracy: 0.8983\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "703/844 [=======================>......] - ETA: 1s - loss: 0.3322 - sparse_categorical_accuracy: 0.8985\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "708/844 [========================>.....] - ETA: 1s - loss: 0.3316 - sparse_categorical_accuracy: 0.8987\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "713/844 [========================>.....] - ETA: 1s - loss: 0.3312 - sparse_categorical_accuracy: 0.8987\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "718/844 [========================>.....] - ETA: 1s - loss: 0.3304 - sparse_categorical_accuracy: 0.8990\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "723/844 [========================>.....] - ETA: 1s - loss: 0.3303 - sparse_categorical_accuracy: 0.8991\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "727/844 [========================>.....] - ETA: 1s - loss: 0.3295 - sparse_categorical_accuracy: 0.8993\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "731/844 [========================>.....] - ETA: 1s - loss: 0.3291 - sparse_categorical_accuracy: 0.8995\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "736/844 [=========================>....] - ETA: 1s - loss: 0.3287 - sparse_categorical_accuracy: 0.8996\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "740/844 [=========================>....] - ETA: 1s - loss: 0.3284 - sparse_categorical_accuracy: 0.8996\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "743/844 [=========================>....] - ETA: 1s - loss: 0.3281 - sparse_categorical_accuracy: 0.8996\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "748/844 [=========================>....] - ETA: 0s - loss: 0.3271 - sparse_categorical_accuracy: 0.9000\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "753/844 [=========================>....] - ETA: 0s - loss: 0.3268 - sparse_categorical_accuracy: 0.8999\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "758/844 [=========================>....] - ETA: 0s - loss: 0.3260 - sparse_categorical_accuracy: 0.9001\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "764/844 [==========================>...] - ETA: 0s - loss: 0.3251 - sparse_categorical_accuracy: 0.9004\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "768/844 [==========================>...] - ETA: 0s - loss: 0.3245 - sparse_categorical_accuracy: 0.9006\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "773/844 [==========================>...] - ETA: 0s - loss: 0.3240 - sparse_categorical_accuracy: 0.9007\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "777/844 [==========================>...] - ETA: 0s - loss: 0.3236 - sparse_categorical_accuracy: 0.9008\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "782/844 [==========================>...] - ETA: 0s - loss: 0.3233 - sparse_categorical_accuracy: 0.9008\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "787/844 [==========================>...] - ETA: 0s - loss: 0.3227 - sparse_categorical_accuracy: 0.9010\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "792/844 [===========================>..] - ETA: 0s - loss: 0.3227 - sparse_categorical_accuracy: 0.9010\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "796/844 [===========================>..] - ETA: 0s - loss: 0.3223 - sparse_categorical_accuracy: 0.9010\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "799/844 [===========================>..] - ETA: 0s - loss: 0.3218 - sparse_categorical_accuracy: 0.9012\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "803/844 [===========================>..] - ETA: 0s - loss: 0.3217 - sparse_categorical_accuracy: 0.9012\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "807/844 [===========================>..] - ETA: 0s - loss: 0.3215 - sparse_categorical_accuracy: 0.9014\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "811/844 [===========================>..] - ETA: 0s - loss: 0.3214 - sparse_categorical_accuracy: 0.9014\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "815/844 [===========================>..] - ETA: 0s - loss: 0.3208 - sparse_categorical_accuracy: 0.9016\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "819/844 [============================>.] - ETA: 0s - loss: 0.3205 - sparse_categorical_accuracy: 0.9017\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "823/844 [============================>.] - ETA: 0s - loss: 0.3201 - sparse_categorical_accuracy: 0.9018\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "827/844 [============================>.] - ETA: 0s - loss: 0.3199 - sparse_categorical_accuracy: 0.9019\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "831/844 [============================>.] - ETA: 0s - loss: 0.3195 - sparse_categorical_accuracy: 0.9020\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "835/844 [============================>.] - ETA: 0s - loss: 0.3193 - sparse_categorical_accuracy: 0.9021\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "839/844 [============================>.] - ETA: 0s - loss: 0.3188 - sparse_categorical_accuracy: 0.9022\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "843/844 [============================>.] - ETA: 0s - loss: 0.3188 - sparse_categorical_accuracy: 0.9022\n",
            "Accuracy has dropped below 96.00%, freezing further pruning.\n",
            "True\n",
            "844/844 [==============================] - 10s 12ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare performance between adaptive pruning and basic pruning\n",
        "print(f\"adaptive Model test accuracy: {adaptive_pruned_model.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "print(f\"pruned Model test accuracy: {pruned_model.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(adaptive_pruned_model) * 100\n",
        "print(f\"adaptive Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(pruned_model) * 100\n",
        "print(f\"Pruned Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "adaptive_pruned_model = sparsity.strip_pruning(adaptive_pruned_model)\n",
        "print('\\n')\n",
        "print(\"Size of gzipped adaptive model: %.2f bytes\" % (get_gzipped_model_size(adaptive_pruned_model)))\n",
        "print(\"Size of gzipped pruned model: %.2f bytes\" % (get_gzipped_model_size(pruned_model_stripped)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W58HA1h35yLa",
        "outputId": "a72936b6-dc30-4351-fbe6-ac8c421b370e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2456 - sparse_categorical_accuracy: 0.9204\n",
            "adaptive Model test accuracy: 0.92%\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9807\n",
            "pruned Model test accuracy: 0.98%\n",
            "adaptive Model sparsity: 89.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Model sparsity: 49.74%\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped adaptive model: 7417.00 bytes\n",
            "Size of gzipped pruned model: 16924.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prune + KD"
      ],
      "metadata": {
        "id": "WRRR8F2Of3AS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation functions"
      ],
      "metadata": {
        "id": "c0Afp4dJgtVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, teacher, student, alpha=0.1, temperature=3, **kwargs):\n",
        "        super(Distiller, self).__init__(**kwargs)\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(self, optimizer, metrics, student_loss_fn, distillation_loss_fn, alpha, temperature, **kwargs):\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics, **kwargs)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.student.compile(optimizer=optimizer, metrics=metrics, loss=self.student_loss_fn)\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher with no gradient tracking\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of the student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Calculate the task-specific loss\n",
        "            task_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "            # Calculate the soft targets and the distillation loss\n",
        "            soft_targets = tf.nn.softmax(teacher_predictions / self.temperature)\n",
        "            student_soft = tf.nn.softmax(student_predictions / self.temperature)\n",
        "            distillation_loss = self.distillation_loss_fn(soft_targets, student_soft)\n",
        "\n",
        "            # Calculate the total loss\n",
        "            total_loss = (1 - self.alpha) * task_loss + self.alpha * distillation_loss * (self.temperature ** 2)\n",
        "\n",
        "        # Compute gradients and update weights\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(total_loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update metrics\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"task_loss\": task_loss, \"distillation_loss\": distillation_loss, \"total_loss\": total_loss})\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of the student\n",
        "        y_pred = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the task-specific loss\n",
        "        task_loss = self.student_loss_fn(y, y_pred)\n",
        "\n",
        "        # Update the metrics\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def call_model(self):\n",
        "      return self.student\n",
        "\n",
        "def train_distill(_student, _teacher, _epoch, x_train = x_train, y_train=y_train, _alpha=0.1, _temp=3):\n",
        "  distiller = Distiller(student=_student, teacher=_teacher)\n",
        "  distiller.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "      student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "      alpha=_alpha,\n",
        "      temperature=_temp,\n",
        "  )\n",
        "\n",
        "  # Distill teacher to student\n",
        "\n",
        "  distiller.fit(x_train, y_train, epochs=_epoch, validation_split=validation_split)\n",
        "  distiller.evaluate(x_test, y_test)\n",
        "\n",
        "  return distiller"
      ],
      "metadata": {
        "id": "_4JJ85kpiIeV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simkd\n",
        "class SimKDDistill(Distiller):\n",
        "  def __init__(self, teacher, student,  alpha=0.1, temperature=3, **kwargs):\n",
        "      super(SimKDDistill, self).__init__(teacher, student,**kwargs)\n",
        "\n",
        "      # Assign weights and biases to the last layer, biases are always the same dimension as number of classes\n",
        "      self.student.layers[-1].set_weights(self.teacher.layers[-1].get_weights())\n",
        "\n",
        "      # Freeze the last layer (prevent it from updating)\n",
        "      self.student.layers[-1].trainable = False\n",
        "\n",
        "def train_simKD(_student, _teacher, _epoch, x_train = x_train, y_train=y_train, _alpha=0.1, _temp=3):\n",
        "  distiller = SimKDDistill(student=_student, teacher=_teacher)\n",
        "  distiller.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "      student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "      alpha=_alpha,\n",
        "      temperature=_temp\n",
        "  )\n",
        "\n",
        "  distiller.fit(x_train, y_train, epochs=_epoch, validation_split=validation_split)\n",
        "  distiller.evaluate(x_test, y_test)\n",
        "  return distiller"
      ],
      "metadata": {
        "id": "IWwe5pH-put4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "a0em5N6mkBtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first of all, we have 2 homogenous dataset and 2 models of the same architecture, they share the same testing dataset"
      ],
      "metadata": {
        "id": "UjwK9b_HgjJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "mid_point = len(x_train) // 2\n",
        "# D1\n",
        "x_train_1 = x_train[:mid_point]\n",
        "y_train_1 = y_train[:mid_point]\n",
        "x_train_2 = x_train[mid_point:]\n",
        "y_train_2 = y_train[mid_point:]\n",
        "\n",
        "# TODO: visualise distribution\n",
        "def print_dist(y_train, name):\n",
        "  unique, counts = np.unique(y_train, return_counts=True)\n",
        "  label_distribution = dict(zip(unique, counts))\n",
        "\n",
        "  # Print the label distribution\n",
        "  print(\"Label Distribution in Training Set \", name, \":\")\n",
        "  for label, count in label_distribution.items():\n",
        "      print(f\"Label {label}: {count} instances\")\n",
        "\n",
        "print_dist(y_train_1, '1')\n",
        "print_dist(y_train_2, '2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFBtGuvf7un",
        "outputId": "95c8cbb4-980a-45c1-9c7b-ac4aaab64325"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution in Training Set  1 :\n",
            "Label 0: 2961 instances\n",
            "Label 1: 3423 instances\n",
            "Label 2: 2948 instances\n",
            "Label 3: 3073 instances\n",
            "Label 4: 2926 instances\n",
            "Label 5: 2709 instances\n",
            "Label 6: 2975 instances\n",
            "Label 7: 3107 instances\n",
            "Label 8: 2875 instances\n",
            "Label 9: 3003 instances\n",
            "Label Distribution in Training Set  2 :\n",
            "Label 0: 2962 instances\n",
            "Label 1: 3319 instances\n",
            "Label 2: 3010 instances\n",
            "Label 3: 3058 instances\n",
            "Label 4: 2916 instances\n",
            "Label 5: 2712 instances\n",
            "Label 6: 2943 instances\n",
            "Label 7: 3158 instances\n",
            "Label 8: 2976 instances\n",
            "Label 9: 2946 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train model 1 on dataset 1"
      ],
      "metadata": {
        "id": "2ViKrne-hhVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = mediumCNN()\n",
        "model1 = trainCNN(model1, 5, x_train = x_train_1, y_train = y_train_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paeqVqSTho1i",
        "outputId": "aaf891f3-5d0b-46d8-d4c9-901fc0863eb2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 5s 6ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.1963 - val_sparse_categorical_accuracy: 0.9367\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1540 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.1305 - val_sparse_categorical_accuracy: 0.9580\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9629 - val_loss: 0.1185 - val_sparse_categorical_accuracy: 0.9647\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.0946 - val_sparse_categorical_accuracy: 0.9733\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 3s 8ms/step - loss: 0.0847 - sparse_categorical_accuracy: 0.9734 - val_loss: 0.0837 - val_sparse_categorical_accuracy: 0.9713\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prune Model1 to Model2 training on dataset 2. ie. model2 weights are initialised with model1 weights"
      ],
      "metadata": {
        "id": "NYeqSEr4kGBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, weights1 = tempfile.mkstemp('.tf')\n",
        "model1.save_weights(weights1)\n",
        "\n",
        "# pruning\n",
        "model2 = mediumCNN()\n",
        "model2.load_weights(weights1)\n",
        "model2 = prune_finetrain(model2, 5, 0.6, x_train = x_train_2, y_train = y_train_2)\n",
        "model2 = sparsity.strip_pruning(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3POrR0WylNMc",
        "outputId": "aa721972-4a98-4b8b-f3db-475f6db7d817"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _12 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 8 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_8 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _13 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 9 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_9 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _14 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_4 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 4 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "422/422 [==============================] - 9s 9ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.0712 - val_sparse_categorical_accuracy: 0.9813\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.0900 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0663 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 5s 11ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.0652 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9763 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9823\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9768 - val_loss: 0.0626 - val_sparse_categorical_accuracy: 0.9823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "relay the knowledge learnt from dataset2 back to model1 with knowledge distillation: model2 is teacher, model1 is student"
      ],
      "metadata": {
        "id": "WUGmIMUPnc5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1_kd = mediumCNN()\n",
        "model1_kd.load_weights(weights1)\n",
        "model1_kd = train_distill(model1_kd, model2, 5, x_train = x_train_1, y_train=y_train_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBIurYRznuRU",
        "outputId": "3c0f3b47-b294-4c55-ab49-75815ba59f2f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "844/844 [==============================] - 8s 6ms/step - sparse_categorical_accuracy: 0.9765 - task_loss: 0.0748 - distillation_loss: 0.0195 - total_loss: 0.0849 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 5s 5ms/step - sparse_categorical_accuracy: 0.9798 - task_loss: 0.0662 - distillation_loss: 0.0157 - total_loss: 0.0738 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 5s 6ms/step - sparse_categorical_accuracy: 0.9814 - task_loss: 0.0588 - distillation_loss: 0.0149 - total_loss: 0.0663 - val_sparse_categorical_accuracy: 0.9750\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 5s 5ms/step - sparse_categorical_accuracy: 0.9840 - task_loss: 0.0552 - distillation_loss: 0.0150 - total_loss: 0.0632 - val_sparse_categorical_accuracy: 0.9797\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 8s 9ms/step - sparse_categorical_accuracy: 0.9841 - task_loss: 0.0519 - distillation_loss: 0.0148 - total_loss: 0.0600 - val_sparse_categorical_accuracy: 0.9787\n",
            "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.9821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_simkd = mediumCNN()\n",
        "model1_simkd.load_weights(weights1)\n",
        "model1_simkd = train_simKD(model1_simkd, model2, 5, x_train = x_train_1, y_train=y_train_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO0he337qbqn",
        "outputId": "0ed6b825-ac11-457b-c34f-e31fad33a899"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "844/844 [==============================] - 8s 7ms/step - sparse_categorical_accuracy: 0.9784 - task_loss: 0.0713 - distillation_loss: 0.0151 - total_loss: 0.0777 - val_sparse_categorical_accuracy: 0.9770\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 4s 5ms/step - sparse_categorical_accuracy: 0.9811 - task_loss: 0.0630 - distillation_loss: 0.0115 - total_loss: 0.0670 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 4s 5ms/step - sparse_categorical_accuracy: 0.9823 - task_loss: 0.0591 - distillation_loss: 0.0116 - total_loss: 0.0636 - val_sparse_categorical_accuracy: 0.9770\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 5s 6ms/step - sparse_categorical_accuracy: 0.9829 - task_loss: 0.0575 - distillation_loss: 0.0116 - total_loss: 0.0621 - val_sparse_categorical_accuracy: 0.9803\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 4s 5ms/step - sparse_categorical_accuracy: 0.9829 - task_loss: 0.0543 - distillation_loss: 0.0117 - total_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9793\n",
            "313/313 [==============================] - 1s 3ms/step - sparse_categorical_accuracy: 0.9820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_plain = mediumCNN()\n",
        "model1_plain.load_weights(weights1)\n",
        "model1_plain = trainCNN(model1_plain, 5, x_train = x_train_1, y_train = y_train_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DijP0wbarn0h",
        "outputId": "2f6b1f37-2df0-4bf2-f142-5ad5d053e5f2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 5s 8ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9768 - val_loss: 0.0776 - val_sparse_categorical_accuracy: 0.9767\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0683 - sparse_categorical_accuracy: 0.9796 - val_loss: 0.0761 - val_sparse_categorical_accuracy: 0.9777\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0757 - val_sparse_categorical_accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.0702 - val_sparse_categorical_accuracy: 0.9783\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.0644 - val_sparse_categorical_accuracy: 0.9777\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments\n",
        "compare the performance of model1 after kd, simkd, raw training\n",
        "- use heterogeneous datasets\n",
        "- use different sized models"
      ],
      "metadata": {
        "id": "PflVy-GHsXTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prune + KD + GAN\n",
        "\n",
        "This prototype replaces the \"public dataset\" D1 with a GAN generated dataset\n",
        "\n",
        "TODO:\n",
        "1. build a MNIST Generating GAN model\n",
        "2. use model2 $($classifier$)$ and D2 as input through GAN to generate a public dataset PD\n",
        "3. connect model1 to PD instead of D1, repeat the KD step from model2 to model1"
      ],
      "metadata": {
        "id": "K2KrL5Hbsyjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prune + KD + GAN + FL\n",
        "This prototype implements the algorithm in a distributed setting\n",
        "TODO:\n",
        "1. implement a FedAvg aggregator/server\n",
        "2. build a centralised FL system with n clients connected to the server\n",
        "3. design experiments to assess accuracy, efficiency, generalisation on homogenoeous data\n",
        "4. repeat experiments on heterogeneous data, identical model sparsity\n",
        "5. repeat experiments on heterogeneous data, different model sparsity, mimicing different computational capability of clients"
      ],
      "metadata": {
        "id": "jFPHnxLEvkoe"
      }
    }
  ]
}