{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrMEG50kUi5NGsgU5nTLLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisW2420/FedDistill/blob/main/Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prototype"
      ],
      "metadata": {
        "id": "j0dInRzQ6HOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "SIyHFXls6LCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIyDUmTG6d22",
        "outputId": "d78dfd8c-e366-4d0c-a842-c27f8b57c797"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/242.5 kB\u001b[0m \u001b[31m794.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/242.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m204.8/242.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "import tf_keras as keras\n",
        "import tempfile\n",
        "from keras.callbacks import EarlyStopping, Callback"
      ],
      "metadata": {
        "id": "ZVBD4_yF6Kaa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "from wandb.keras import WandbMetricsLogger"
      ],
      "metadata": {
        "id": "iozTZlIe6h5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset"
      ],
      "metadata": {
        "id": "6v6pgRmS6Px3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the train and test dataset.\n",
        "batch_size = 64\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
        "validation_split = 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk66OzPv6GR-",
        "outputId": "2fc5a264-1439-42a0-c66e-f5cec0792a4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "7ih2fKVsE7Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smallCNN():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(28, 28, 1)),\n",
        "          keras.layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(10),\n",
        "      ],\n",
        "      name=\"smallcnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def mediumCNN():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(28, 28, 1)),\n",
        "          keras.layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(10),\n",
        "      ],\n",
        "      name=\"mediumcnn\",\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def bigCNN():\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=(28, 28, 1)),\n",
        "          keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.ReLU(),\n",
        "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "          keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(10),\n",
        "      ],\n",
        "      name=\"bigcnn\",\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "EpzZr20vE6-O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gzk8Qaec5Qyt"
      },
      "outputs": [],
      "source": [
        "# early stopping when training converges on validation loss\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.001,  # only consider as improvement significant changes\n",
        "    patience=2,      # number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='min'        # 'min' because we want to minimize the loss\n",
        ")\n",
        "\n",
        "def trainCNN_weights(model, _epoch):\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model.fit(x_train, y_train, epochs=_epoch,validation_split=validation_split, callbacks=[early_stopping])\n",
        "  model.evaluate(x_test, y_test)\n",
        "\n",
        "  return model\n",
        "\n",
        "  # _, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "\n",
        "  # model.save_weights(pretrained_weights)\n",
        "\n",
        "  # return pretrained_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pruning"
      ],
      "metadata": {
        "id": "TjnfgMrEY3Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic implementation"
      ],
      "metadata": {
        "id": "83t9MJb2ZOTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functions\n",
        "def prune_finetrain(base_model, _epochs):\n",
        "  callbacks = [\n",
        "      sparsity.UpdatePruningStep(),\n",
        "      early_stopping\n",
        "  ]\n",
        "\n",
        "  model_for_pruning = sparsity.prune_low_magnitude(base_model) #default constant sparsity of 50%\n",
        "  model_for_pruning.summary()\n",
        "\n",
        "  model_for_pruning.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model_for_pruning.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      validation_split=validation_split,\n",
        "      callbacks=callbacks,\n",
        "      epochs=_epochs,\n",
        "  )\n",
        "\n",
        "  return model_for_pruning\n",
        "\n",
        "def get_model_sparsity(model):\n",
        "    total_weights = 0\n",
        "    zero_weights = 0\n",
        "    for weight in model.get_weights():\n",
        "        total_weights += weight.size\n",
        "        zero_weights += np.count_nonzero(weight == 0)\n",
        "    return zero_weights / total_weights\n",
        "\n",
        "def get_gzipped_model_size(model):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, keras_file = tempfile.mkstemp('.h5')\n",
        "  model.save(keras_file, include_optimizer=False)\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(keras_file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "metadata": {
        "id": "DnzKU0g0hsbj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training base model\n",
        "\n",
        "model = mediumCNN()\n",
        "model = trainCNN_weights(model, 5)\n",
        "_, pretrained_weights = tempfile.mkstemp('.tf')\n",
        "model.save_weights(pretrained_weights)\n",
        "\n",
        "# pruning\n",
        "base_model = mediumCNN()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "pruned_model = prune_finetrain(base_model, 5)\n",
        "\n",
        "# continue training base model for performance comparison\n",
        "base_model_copy = mediumCNN()\n",
        "base_model_copy.load_weights(pretrained_weights)\n",
        "base_model_copy = trainCNN_weights(base_model_copy, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdg3hXYGkxo4",
        "outputId": "7a57156e-535a-4765-881d-7aacb8ea33dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 28s 5ms/step - loss: 0.2760 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.0752 - val_sparse_categorical_accuracy: 0.9783\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9725 - val_loss: 0.0616 - val_sparse_categorical_accuracy: 0.9823\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0525 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9817 - val_loss: 0.0465 - val_sparse_categorical_accuracy: 0.9867\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9848\n",
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _3 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_2 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _4 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 3 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_3 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _5 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_1 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 21s 7ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0494 - val_sparse_categorical_accuracy: 0.9862\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0485 - val_sparse_categorical_accuracy: 0.9857\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0454 - val_sparse_categorical_accuracy: 0.9863\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0418 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.0451 - val_sparse_categorical_accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0397 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0453 - val_sparse_categorical_accuracy: 0.9865\n",
            "Epoch 5: early stopping\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 9s 4ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9845\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0501 - val_sparse_categorical_accuracy: 0.9862\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9867 - val_loss: 0.0449 - val_sparse_categorical_accuracy: 0.9865\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9874 - val_loss: 0.0530 - val_sparse_categorical_accuracy: 0.9840\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0436 - val_sparse_categorical_accuracy: 0.9875\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_stripped = sparsity.strip_pruning(pruned_model)\n",
        "print(\"final model\")\n",
        "pruned_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4uzSF34rnI7",
        "outputId": "a5f0b75a-6ce7-4171-f819-8ef2182cbe20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final model\n",
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _3 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_2 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _4 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 3 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_3 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _5 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_1 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare accuracy, sparsity and file size\n",
        "print(f\"Base Model test accuracy: {base_model_copy.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "print(f\"Pruned Model test accuracy: {pruned_model.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(base_model_copy) * 100\n",
        "print(f\"Base Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(pruned_model) * 100\n",
        "print(f\"Pruned Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "print('\\n')\n",
        "print(\"Size of gzipped base model: %.2f bytes\" % (get_gzipped_model_size(base_model_copy)))\n",
        "print(\"Size of gzipped pruned model: %.2f bytes\" % (get_gzipped_model_size(pruned_model_stripped)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDY-wn3mp2xd",
        "outputId": "cffcfaa4-6f17-4eb3-b910-653207124c41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9854\n",
            "Base Model test accuracy: 0.99%\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0405 - sparse_categorical_accuracy: 0.9873\n",
            "Pruned Model test accuracy: 0.99%\n",
            "Base Model sparsity: 0.00%\n",
            "Pruned Model sparsity: 49.74%\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of gzipped base model: 25653.00 bytes\n",
            "Size of gzipped pruned model: 16903.00 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning to as small as possible with > 99.5% accuracy as best"
      ],
      "metadata": {
        "id": "4X1KGhoAv9QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function\n",
        "# save good performance ones\n",
        "class SaveSparseModelCallback(Callback):\n",
        "    def __init__(self, model, path='best_sparse_model.h5'):\n",
        "        super(SaveSparseModelCallback, self).__init__()\n",
        "        self.model = model\n",
        "        self.best_accuracy = 0.98\n",
        "        self.path = path\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        current_accuracy = logs.get('sparse_categorical_accuracy')\n",
        "        if current_accuracy > self.best_accuracy:\n",
        "            print(f\"batch {batch + 1}: training accuracy {current_accuracy*100:.2f}% exceeds {self.best_accuracy*100:.2f}%. Saving model.\")\n",
        "            self.model = sparsity.strip_pruning(self.model)\n",
        "            self.model.save(self.path)\n",
        "            self.best_accuracy = current_accuracy\n",
        "\n",
        "\n",
        "def prune_finetrain(base_model, _epochs):\n",
        "  steps_per_epoch = len(x_train)*(1-validation_split) // batch_size\n",
        "  print('steps_per_epoch: ', steps_per_epoch)\n",
        "  pruning_schedule = sparsity.PolynomialDecay(initial_sparsity=0.30, final_sparsity=0.60,\n",
        "                                              begin_step=0, end_step=3000) # increase sparsity\n",
        "\n",
        "\n",
        "  model_for_pruning = sparsity.prune_low_magnitude(base_model\n",
        "                                                  , pruning_schedule=pruning_schedule\n",
        "                                                   )\n",
        "  model_for_pruning.summary()\n",
        "\n",
        "\n",
        "  callbacks = [\n",
        "    sparsity.UpdatePruningStep(),\n",
        "    sparsity.PruningSummaries(log_dir='/path/to/logs'),\n",
        "    # SaveSparseModelCallback(pruned_model),\n",
        "    # early_stopping\n",
        "]\n",
        "\n",
        "\n",
        "  model_for_pruning.compile(\n",
        "        optimizer='adam',\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "  model_for_pruning.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=batch_size,\n",
        "      validation_split=validation_split,\n",
        "      callbacks=callbacks,\n",
        "      epochs=_epochs,\n",
        "  )\n",
        "\n",
        "  return model_for_pruning"
      ],
      "metadata": {
        "id": "QBV-LExY3ll8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adaptive pruning\n",
        "base_model = mediumCNN()\n",
        "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
        "adaptive_pruned_model = prune_finetrain(base_model, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bpekp7an6Afn",
        "outputId": "20578c8c-4713-4df0-beaa-701d2140b0c4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps_per_epoch:  843.0\n",
            "Model: \"mediumcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 14, 14, 8)         154       \n",
            " _39 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 14, 14, 8)         1         \n",
            " 26 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 14, 14, 8)         1         \n",
            " oling2d_26 (PruneLowMagnit                                      \n",
            " ude)                                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 7, 7, 16)          2322      \n",
            " _40 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_  (None, 7, 7, 16)          1         \n",
            " 27 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 7, 7, 16)          1         \n",
            " oling2d_27 (PruneLowMagnit                                      \n",
            " ude)                                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 4, 4, 16)          4626      \n",
            " _41 (PruneLowMagnitude)                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 256)               1         \n",
            " n_13 (PruneLowMagnitude)                                        \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                5132      \n",
            " 13 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12239 (47.84 KB)\n",
            "Trainable params: 6138 (23.98 KB)\n",
            "Non-trainable params: 6101 (23.87 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "   6/1688 [..............................] - ETA: 17s - loss: 0.0477 - sparse_categorical_accuracy: 0.9896    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0091s vs `on_train_batch_end` time: 0.0163s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1688/1688 [==============================] - 16s 7ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0558 - val_sparse_categorical_accuracy: 0.9832\n",
            "Epoch 2/3\n",
            " 162/1688 [=>............................] - ETA: 15s - loss: 0.0519 - sparse_categorical_accuracy: 0.9848"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-63c9790cd36e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmediumCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# optional but recommended.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0madaptive_pruned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_finetrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-a77a0e28105e>\u001b[0m in \u001b[0;36mprune_finetrain\u001b[0;34m(base_model, _epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m   )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   model_for_pruning.fit(\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                         ):\n\u001b[1;32m   1803\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare performance between adaptive pruning and basic pruning\n",
        "print(f\"adaptive Model test accuracy: {adaptive_pruned_model.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "print(f\"pruned Model test accuracy: {pruned_model.evaluate(x_test, y_test)[1]:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(adaptive_pruned_model) * 100\n",
        "print(f\"adaptive Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "sparsity_percentage = get_model_sparsity(pruned_model) * 100\n",
        "print(f\"Pruned Model sparsity: {sparsity_percentage:.2f}%\")\n",
        "\n",
        "adaptive_pruned_model = sparsity.strip_pruning(adaptive_pruned_model)\n",
        "print('\\n')\n",
        "print(\"Size of gzipped adaptive model: %.2f bytes\" % (get_gzipped_model_size(adaptive_pruned_model)))\n",
        "print(\"Size of gzipped pruned model: %.2f bytes\" % (get_gzipped_model_size(pruned_model_stripped)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W58HA1h35yLa",
        "outputId": "e5889a61-b6c4-4f5c-ea43-e56b63dc4555"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Size of gzipped adaptive model: 14595.00 bytes\n",
            "Size of gzipped pruned model: 16903.00 bytes\n"
          ]
        }
      ]
    }
  ]
}